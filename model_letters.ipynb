{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, MaxPooling1D, Dropout, MaxPooling2D, Convolution2D\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_letters.csv\")\n",
    "test_data = pd.read_csv(\"data/validation_letters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id target\n",
       "0            1      a\n",
       "1            2      a\n",
       "2            3      a\n",
       "3            4      a\n",
       "4            6      a"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train data--------------------\n",
      "Cantidad de filas : 128\n",
      "Frases unicas : ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's'\n",
      " 't' 'u' 'v' 'w' 'x' 'y']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Train data--------------------\")\n",
    "print(f\"Cantidad de filas : {train_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {train_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation data--------------------\n",
      "Cantidad de filas : 24\n",
      "Frases unicas : ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's'\n",
      " 't' 'u' 'v' 'w' 'x' 'y']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Validation data--------------------\")\n",
    "print(f\"Cantidad de filas : {test_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {test_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (list(train_data.target.unique()) != list(test_data.target.unique())):\n",
    "    raise ValueError(\"Error between target and train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>85.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>50.382706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>83.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>129.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_id\n",
       "count   128.000000\n",
       "mean     85.265625\n",
       "std      50.382706\n",
       "min       1.000000\n",
       "25%      43.500000\n",
       "50%      83.500000\n",
       "75%     129.250000\n",
       "max     170.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo se obtienen 20 indices de las coordenadas x y y, ya que son las unicas que han sido altamente entrenadas del modelo mediapipe de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_cols():\n",
    "    cols = []\n",
    "\n",
    "    for i in range(21):\n",
    "        # cols.append(f'x_Right_hand_{i}')\n",
    "        # cols.append(f'y_Right_hand_{i}')\n",
    "        cols.append(f'x_Left_hand_{i}')\n",
    "        cols.append(f'y_Left_hand_{i}')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_letters.csv\")\n",
    "df_test = df[df['sequence_id'].isin(test_data['sequence_id'])]\n",
    "df_train = df[df['sequence_id'].isin(train_data['sequence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "      <th>x_Left_hand_0</th>\n",
       "      <th>y_Left_hand_0</th>\n",
       "      <th>x_Left_hand_1</th>\n",
       "      <th>y_Left_hand_1</th>\n",
       "      <th>x_Left_hand_2</th>\n",
       "      <th>y_Left_hand_2</th>\n",
       "      <th>x_Left_hand_3</th>\n",
       "      <th>y_Left_hand_3</th>\n",
       "      <th>...</th>\n",
       "      <th>x_Left_hand_16</th>\n",
       "      <th>y_Left_hand_16</th>\n",
       "      <th>x_Left_hand_17</th>\n",
       "      <th>y_Left_hand_17</th>\n",
       "      <th>x_Left_hand_18</th>\n",
       "      <th>y_Left_hand_18</th>\n",
       "      <th>x_Left_hand_19</th>\n",
       "      <th>y_Left_hand_19</th>\n",
       "      <th>x_Left_hand_20</th>\n",
       "      <th>y_Left_hand_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0.530948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715785</td>\n",
       "      <td>0.944666</td>\n",
       "      <td>0.868372</td>\n",
       "      <td>0.737896</td>\n",
       "      <td>0.921069</td>\n",
       "      <td>0.546306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544049</td>\n",
       "      <td>0.777359</td>\n",
       "      <td>0.379488</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.403089</td>\n",
       "      <td>0.486595</td>\n",
       "      <td>0.425640</td>\n",
       "      <td>0.630759</td>\n",
       "      <td>0.439509</td>\n",
       "      <td>0.707957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>0.598715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817269</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.907771</td>\n",
       "      <td>0.568508</td>\n",
       "      <td>0.940256</td>\n",
       "      <td>0.383617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604673</td>\n",
       "      <td>0.687549</td>\n",
       "      <td>0.428759</td>\n",
       "      <td>0.565205</td>\n",
       "      <td>0.488588</td>\n",
       "      <td>0.429457</td>\n",
       "      <td>0.528684</td>\n",
       "      <td>0.529194</td>\n",
       "      <td>0.526195</td>\n",
       "      <td>0.620994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0.699040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855275</td>\n",
       "      <td>0.846713</td>\n",
       "      <td>0.927487</td>\n",
       "      <td>0.655646</td>\n",
       "      <td>0.931123</td>\n",
       "      <td>0.462656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683310</td>\n",
       "      <td>0.719400</td>\n",
       "      <td>0.607122</td>\n",
       "      <td>0.609145</td>\n",
       "      <td>0.574001</td>\n",
       "      <td>0.512297</td>\n",
       "      <td>0.590989</td>\n",
       "      <td>0.615578</td>\n",
       "      <td>0.620398</td>\n",
       "      <td>0.693777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>0.634597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.903572</td>\n",
       "      <td>0.907139</td>\n",
       "      <td>0.784950</td>\n",
       "      <td>0.954674</td>\n",
       "      <td>0.676814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645475</td>\n",
       "      <td>0.802731</td>\n",
       "      <td>0.455929</td>\n",
       "      <td>0.711337</td>\n",
       "      <td>0.475522</td>\n",
       "      <td>0.609587</td>\n",
       "      <td>0.522922</td>\n",
       "      <td>0.668138</td>\n",
       "      <td>0.547249</td>\n",
       "      <td>0.736916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>0.623369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.788632</td>\n",
       "      <td>0.951898</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>0.803502</td>\n",
       "      <td>0.940904</td>\n",
       "      <td>0.680150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618199</td>\n",
       "      <td>0.885746</td>\n",
       "      <td>0.434740</td>\n",
       "      <td>0.745519</td>\n",
       "      <td>0.459325</td>\n",
       "      <td>0.661971</td>\n",
       "      <td>0.500133</td>\n",
       "      <td>0.754159</td>\n",
       "      <td>0.523836</td>\n",
       "      <td>0.827396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id target  x_Left_hand_0  y_Left_hand_0  x_Left_hand_1  \\\n",
       "0            1      a       0.530948            1.0       0.715785   \n",
       "1            2      a       0.598715            1.0       0.817269   \n",
       "2            3      a       0.699040            1.0       0.855275   \n",
       "3            4      a       0.634597            1.0       0.810858   \n",
       "4            5      a       0.623369            1.0       0.788632   \n",
       "\n",
       "   y_Left_hand_1  x_Left_hand_2  y_Left_hand_2  x_Left_hand_3  y_Left_hand_3  \\\n",
       "0       0.944666       0.868372       0.737896       0.921069       0.546306   \n",
       "1       0.787746       0.907771       0.568508       0.940256       0.383617   \n",
       "2       0.846713       0.927487       0.655646       0.931123       0.462656   \n",
       "3       0.903572       0.907139       0.784950       0.954674       0.676814   \n",
       "4       0.951898       0.908468       0.803502       0.940904       0.680150   \n",
       "\n",
       "   ...  x_Left_hand_16  y_Left_hand_16  x_Left_hand_17  y_Left_hand_17  \\\n",
       "0  ...        0.544049        0.777359        0.379488        0.578000   \n",
       "1  ...        0.604673        0.687549        0.428759        0.565205   \n",
       "2  ...        0.683310        0.719400        0.607122        0.609145   \n",
       "3  ...        0.645475        0.802731        0.455929        0.711337   \n",
       "4  ...        0.618199        0.885746        0.434740        0.745519   \n",
       "\n",
       "   x_Left_hand_18  y_Left_hand_18  x_Left_hand_19  y_Left_hand_19  \\\n",
       "0        0.403089        0.486595        0.425640        0.630759   \n",
       "1        0.488588        0.429457        0.528684        0.529194   \n",
       "2        0.574001        0.512297        0.590989        0.615578   \n",
       "3        0.475522        0.609587        0.522922        0.668138   \n",
       "4        0.459325        0.661971        0.500133        0.754159   \n",
       "\n",
       "   x_Left_hand_20  y_Left_hand_20  \n",
       "0        0.439509        0.707957  \n",
       "1        0.526195        0.620994  \n",
       "2        0.620398        0.693777  \n",
       "3        0.547249        0.736916  \n",
       "4        0.523836        0.827396  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_test) == len(test_data))\n",
    "print(len(df_train) == len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the lengths of the video sequences\n",
    "video_lengths = df.groupby('sequence_id').size()\n",
    "max_seq_length = video_lengths.max()\n",
    "# max_seq_length = 30\n",
    "# Plot the histogram\n",
    "plt.hist(video_lengths, bins=30)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Video Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Video Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a one-hot encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_videos(df):\n",
    "    # Create a new DataFrame to store the filled rows\n",
    "    filled_df = pd.DataFrame()\n",
    "    target = []\n",
    "\n",
    "\n",
    "    # Iterate over each group and fill remaining rows with zero\n",
    "    for _, group in df.groupby('sequence_id'):\n",
    "        remaining_rows = max_seq_length - len(group)\n",
    "        zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "        zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "        zeros_df['target'] = group['target'].unique()[0]\n",
    "        group = pd.concat([group, zeros_df])\n",
    "    \n",
    "        filled_df = filled_df.append(group)\n",
    "        target.append(group[\"target\"].unique()[0])\n",
    "        \n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df, target\n",
    "\n",
    "def padding_labels(target):\n",
    "    integer_encoded = label_encoder.fit_transform(target)\n",
    "    integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "\n",
    "    # Encode the word \"Hello\"\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)  # sparse=False to get a numpy array as output\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, target = padding_videos(df_train)\n",
    "y_train = padding_labels(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "del X_train[\"sequence_id\"] \n",
    "del X_train[\"target\"] \n",
    "\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24\n"
     ]
    }
   ],
   "source": [
    "X_test, target = padding_videos(df_test)\n",
    "y_test = padding_labels(target)\n",
    "del X_test[\"sequence_id\"] \n",
    "del X_test[\"target\"] \n",
    "\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train) + len(y_test) == len(df[\"sequence_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples_train = int(len(X_train)/max_seq_length)\n",
    "# num_features_train = len(get_needed_cols())\n",
    "num_classes_train = len(y_train[1])\n",
    "\n",
    "# X_train = X_train.values.reshape(num_samples_train, max_seq_length, num_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = flat_X(X_train)\n",
    "# X_test = flat_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (128, 42) (128, 24)\n",
      "Test: (24, 42) (24, 24)\n"
     ]
    }
   ],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "La entrada son las coordenadas de las manos. Cada video cuenta con n cantidad de filas, 84 columnas (21 columnas por cada coordenada y por ambas manos).\n",
    "La salida es la frase. La frase se representa por un entero que da el one hot encoder.\n",
    "\n",
    "Se usa convoluciones para resaltar las caracteristicas en la entrada. Debido a que la entrada son coordenadas normalizadas de un video, se supone que funciona igual que si la entrada fuera una imagen. Estas redes extraen caracteristicas de forma automatica para clasificar objetos luego. Al buscar patrones, se espera que pueda predecir un video que ya ha sido entrenado previamente.\n",
    "\n",
    "Se reduce el tamaño de la entrada haciendo uso de max pooling y flatten.\n",
    "\n",
    "Se hace uso de Dense para conectar entradas con salidas.\n",
    "\n",
    "Se hace uso de Dropout para evitar el sobreajuste.\n",
    "\n",
    "Relu elimina negativos. \n",
    "Sigmoid nos ayuda a obtener la probabilidad de que un ejemplo pertenezca a la clase positiva.\n",
    "Softmax hace clasificacion multiclase (en nuestro caso las palabras a predecir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length, num_features_train)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(num_classes_train, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add input layer with appropriate input shape (84 features)\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, activation='relu', input_shape=(len(get_needed_cols()),)))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# # Output layer (adjust units according to your task)\n",
    "# model.add(Dense(num_classes_train, activation='softmax'))  # For classification, or 'linear' for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input layer with appropriate input shape (84 features)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(len(get_needed_cols()),)))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "\n",
    "# Output layer (adjust units according to your task)\n",
    "model.add(Dense(num_classes_train, activation='softmax'))  # For classification, or 'linear' for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.2345 - accuracy: 0.0156\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.2081 - accuracy: 0.0312\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1798 - accuracy: 0.0547\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1725 - accuracy: 0.0469\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1717 - accuracy: 0.0547\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1682 - accuracy: 0.0547\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1223 - accuracy: 0.1016\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1255 - accuracy: 0.0781\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1121 - accuracy: 0.1094\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1077 - accuracy: 0.0781\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.0915 - accuracy: 0.0938\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.0703 - accuracy: 0.0781\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.0445 - accuracy: 0.0859\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.0143 - accuracy: 0.0859\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.9585 - accuracy: 0.1250\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.9652 - accuracy: 0.1172\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.8990 - accuracy: 0.1094\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.9212 - accuracy: 0.1172\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.8913 - accuracy: 0.1797\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.8383 - accuracy: 0.1406\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.7706 - accuracy: 0.1719\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.7461 - accuracy: 0.1484\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.6633 - accuracy: 0.1797\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.6579 - accuracy: 0.1562\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.5952 - accuracy: 0.2031\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.5143 - accuracy: 0.2266\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.4660 - accuracy: 0.2031\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.5034 - accuracy: 0.2422\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.4133 - accuracy: 0.2656\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.3956 - accuracy: 0.2344\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.3529 - accuracy: 0.2812\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2992 - accuracy: 0.2188\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1341 - accuracy: 0.3203\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1374 - accuracy: 0.2891\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1147 - accuracy: 0.2656\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.1234 - accuracy: 0.2969\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.0765 - accuracy: 0.3125\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.0286 - accuracy: 0.3047\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.0317 - accuracy: 0.3047\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9524 - accuracy: 0.3125\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9847 - accuracy: 0.3594\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.8837 - accuracy: 0.3828\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9482 - accuracy: 0.3438\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9363 - accuracy: 0.3359\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.8904 - accuracy: 0.4219\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9345 - accuracy: 0.3672\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.8771 - accuracy: 0.3438\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7209 - accuracy: 0.4453\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.8586 - accuracy: 0.3672\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7439 - accuracy: 0.4219\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6719 - accuracy: 0.4297\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.6186 - accuracy: 0.4688\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5959 - accuracy: 0.4453\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.6608 - accuracy: 0.4219\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.7082 - accuracy: 0.3984\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5052 - accuracy: 0.4453\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5051 - accuracy: 0.5000\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5653 - accuracy: 0.4688\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5115 - accuracy: 0.4297\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5975 - accuracy: 0.4062\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5983 - accuracy: 0.4375\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4179 - accuracy: 0.4844\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4291 - accuracy: 0.4922\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.4766\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4761 - accuracy: 0.4062\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4503 - accuracy: 0.4375\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3060 - accuracy: 0.5391\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3792 - accuracy: 0.4453\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.4922\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3506 - accuracy: 0.5703\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3863 - accuracy: 0.5000\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2698 - accuracy: 0.5859\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2387 - accuracy: 0.5391\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4005 - accuracy: 0.5156\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1963 - accuracy: 0.5625\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3594 - accuracy: 0.5703\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2908 - accuracy: 0.5391\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2870 - accuracy: 0.5234\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3273 - accuracy: 0.4766\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3014 - accuracy: 0.4766\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2296 - accuracy: 0.6172\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3392 - accuracy: 0.4922\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2916 - accuracy: 0.5234\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2120 - accuracy: 0.5078\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1831 - accuracy: 0.5781\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0536 - accuracy: 0.6328\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2274 - accuracy: 0.5156\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1777 - accuracy: 0.5469\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1943 - accuracy: 0.5703\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2512 - accuracy: 0.5000\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0457 - accuracy: 0.6328\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1027 - accuracy: 0.6016\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0813 - accuracy: 0.5938\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0979 - accuracy: 0.5938\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1551 - accuracy: 0.5938\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1103 - accuracy: 0.6250\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0943 - accuracy: 0.6016\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1321 - accuracy: 0.5781\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1283 - accuracy: 0.5859\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0552 - accuracy: 0.6094\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0206 - accuracy: 0.6172\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9521 - accuracy: 0.6484\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0882 - accuracy: 0.6328\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0661 - accuracy: 0.6406\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0803 - accuracy: 0.5781\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0374 - accuracy: 0.6250\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9915 - accuracy: 0.6172\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.6250\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9057 - accuracy: 0.6562\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9661 - accuracy: 0.6797\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0029 - accuracy: 0.6016\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9276 - accuracy: 0.7031\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9437 - accuracy: 0.6641\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9895 - accuracy: 0.6406\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0451 - accuracy: 0.5781\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8423 - accuracy: 0.6719\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9001 - accuracy: 0.6797\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8422 - accuracy: 0.6719\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9849 - accuracy: 0.6172\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.6797\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0125 - accuracy: 0.6016\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9643 - accuracy: 0.6016\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8521 - accuracy: 0.7266\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8913 - accuracy: 0.6875\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8836 - accuracy: 0.6875\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8754 - accuracy: 0.6875\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9636 - accuracy: 0.6250\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8663 - accuracy: 0.6797\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8204 - accuracy: 0.7109\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8451 - accuracy: 0.6797\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8730 - accuracy: 0.6641\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9112 - accuracy: 0.6484\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8074 - accuracy: 0.6875\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0335 - accuracy: 0.5625\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9220 - accuracy: 0.6641\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7879 - accuracy: 0.7500\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8745 - accuracy: 0.6953\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8160 - accuracy: 0.6953\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.7109\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8496 - accuracy: 0.6875\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8406 - accuracy: 0.7266\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9160 - accuracy: 0.6875\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7898 - accuracy: 0.7188\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8554 - accuracy: 0.6562\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9219 - accuracy: 0.6484\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9244 - accuracy: 0.5703\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8837 - accuracy: 0.6562\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7578 - accuracy: 0.7422\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8314 - accuracy: 0.6250\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7973 - accuracy: 0.6797\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7809 - accuracy: 0.6406\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8239 - accuracy: 0.6953\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7551 - accuracy: 0.6953\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.7422\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7760 - accuracy: 0.6875\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7749 - accuracy: 0.6641\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8066 - accuracy: 0.6719\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8774 - accuracy: 0.6250\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7550 - accuracy: 0.7188\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.7500\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7758 - accuracy: 0.7266\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7697 - accuracy: 0.7188\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7583 - accuracy: 0.7188\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7612 - accuracy: 0.7031\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7333 - accuracy: 0.7578\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9147 - accuracy: 0.6562\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8360 - accuracy: 0.6953\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7675 - accuracy: 0.7422\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.7891\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.7109\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7463 - accuracy: 0.6406\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.7891\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.7656\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.7734\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.7188\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.7812\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7594 - accuracy: 0.7422\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.7500\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7578\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8033 - accuracy: 0.6797\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7768 - accuracy: 0.6797\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7994 - accuracy: 0.7031\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.7266\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.7031\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.7422\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.7578\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6260 - accuracy: 0.7969\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.7578\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7812\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.7734\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.8047\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.7422\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.8047\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.8125\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.7578\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.7578\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8010 - accuracy: 0.6875\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.7031\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.8359\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7578\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.7734\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.7266\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5941 - accuracy: 0.7812\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.7344\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.7422\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.7891\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.7266\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7578\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7891\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.7969\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.7891\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.7656\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.7734\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7891\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.7891\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.7266\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.7344\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7734\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.7266\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.8125\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.7578\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.7344\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.7578\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6797\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8203\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5491 - accuracy: 0.7578\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.7500\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.8047\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7969\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7891\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7812\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.7891\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8281\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7812\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.7812\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.8047\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.8125\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.7891\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8125\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8438\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7734\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.8047\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.7734\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.7266\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7891\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.7969\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.8125\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7969\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6875\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.8203\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.7266\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.8125\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7656\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8594\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7734\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.8125\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.8047\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.8047\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7891\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.7656\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.8125\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7734\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.7969\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.8203\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.8359\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8516\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.8281\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.8281\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8203\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7812\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.8125\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.8203\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7891\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7812\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.8047\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8516\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.8047\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.8359\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8203\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8125\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8516\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.8125\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8672\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8359\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.8438\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.7734\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.8359\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.8047\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.8281\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.8359\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7891\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7969\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8594\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.8672\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8516\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.8359\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8516\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.8203\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8281\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8750\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6901 - accuracy: 0.8333\n",
      "Test accuracy: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=300, batch_size=8)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Find the most likely prediction for each sample\n",
    "most_likely_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3, 11,  5,  6,  7,  8, 19, 10, 11, 12,  4, 14, 15, 16,\n",
       "       12, 18, 19, 20, 21, 22, 23], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = label_encoder.inverse_transform(most_likely_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels = train_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctamente predicha:  a\n",
      "Correctamente predicha:  b\n",
      "Correctamente predicha:  c\n",
      "Correctamente predicha:  d\n",
      "Correctamente predicha:  f\n",
      "Correctamente predicha:  g\n",
      "Correctamente predicha:  h\n",
      "Correctamente predicha:  i\n",
      "Correctamente predicha:  l\n",
      "Correctamente predicha:  m\n",
      "Correctamente predicha:  n\n",
      "Correctamente predicha:  p\n",
      "Correctamente predicha:  q\n",
      "Correctamente predicha:  r\n",
      "Correctamente predicha:  t\n",
      "Correctamente predicha:  u\n",
      "Correctamente predicha:  v\n",
      "Correctamente predicha:  w\n",
      "Correctamente predicha:  x\n",
      "Correctamente predicha:  y\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(predicted_labels)):\n",
    "    if (predicted_labels[i] == expected_labels[i]):\n",
    "        correct += 1\n",
    "        print(\"Correctamente predicha: \", predicted_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct >>  20\n",
      "Ratio >>  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct >> \", correct)\n",
    "print(\"Ratio >> \", str(correct/len(test_data.target.unique())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
