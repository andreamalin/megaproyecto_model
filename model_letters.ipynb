{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_letters.csv\")\n",
    "test_data = pd.read_csv(\"data/validation_letters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id target\n",
       "0            1      o\n",
       "1            2      e\n",
       "2            3      y\n",
       "3            4      h\n",
       "4            5      k"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train data--------------------\n",
      "Cantidad de filas : 183\n",
      "Frases unicas : ['a', 'b', 'c', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ñ']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Train data--------------------\")\n",
    "print(f\"Cantidad de filas : {train_data.shape[0]}\")\n",
    "train_letters = list(train_data.target.unique())\n",
    "train_letters.sort()\n",
    "print(f\"Frases unicas : {train_letters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation data--------------------\n",
      "Cantidad de filas : 23\n",
      "Frases unicas : ['a', 'b', 'c', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ñ']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Validation data--------------------\")\n",
    "print(f\"Cantidad de filas : {test_data.shape[0]}\")\n",
    "val_letters = list(test_data.target.unique())\n",
    "val_letters.sort()\n",
    "print(f\"Frases unicas : {val_letters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (train_letters != val_letters):\n",
    "    raise ValueError(\"Error between target and train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo se obtienen 20 indices de las coordenadas x y y, ya que son las unicas que han sido altamente entrenadas del modelo mediapipe de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_cols():\n",
    "    cols = []\n",
    "\n",
    "    for i in range(21):\n",
    "        # cols.append(f'x_Right_hand_{i}')\n",
    "        # cols.append(f'y_Right_hand_{i}')\n",
    "        cols.append(f'x_Left_hand_{i}')\n",
    "        cols.append(f'y_Left_hand_{i}')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_letters.csv\")\n",
    "df_test = df[df['sequence_id'].isin(test_data['sequence_id'])]\n",
    "df_train = df[df['sequence_id'].isin(train_data['sequence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(df_test) == len(test_data))\n",
    "print(len(df_train) == len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the lengths of the video sequences\n",
    "video_lengths = df.groupby('sequence_id').size()\n",
    "max_seq_length = video_lengths.max()\n",
    "# max_seq_length = 30\n",
    "# Plot the histogram\n",
    "plt.hist(video_lengths, bins=30)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Video Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Video Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a one-hot encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_videos(df):\n",
    "    # Create a new DataFrame to store the filled rows\n",
    "    filled_df = pd.DataFrame()\n",
    "    target = []\n",
    "\n",
    "\n",
    "    # Iterate over each group and fill remaining rows with zero\n",
    "    for _, group in df.groupby('sequence_id'):\n",
    "        remaining_rows = max_seq_length - len(group)\n",
    "        zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "        zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "        zeros_df['target'] = group['target'].unique()[0]\n",
    "        group = pd.concat([group, zeros_df])\n",
    "    \n",
    "        filled_df = filled_df.append(group)\n",
    "        target.append(group[\"target\"].unique()[0])\n",
    "        \n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df, target\n",
    "\n",
    "def padding_labels(target):\n",
    "    integer_encoded = label_encoder.fit_transform(target)\n",
    "    integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "\n",
    "    # Encode the word \"Hello\"\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)  # sparse=False to get a numpy array as output\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, target = padding_videos(df_train)\n",
    "y_train = padding_labels(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del X_train[\"sequence_id\"] \n",
    "del X_train[\"target\"] \n",
    "\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, target = padding_videos(df_test)\n",
    "y_test = padding_labels(target)\n",
    "del X_test[\"sequence_id\"] \n",
    "del X_test[\"target\"] \n",
    "\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train) + len(y_test) == len(df[\"sequence_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples_train = int(len(X_train)/max_seq_length)\n",
    "# num_features_train = len(get_needed_cols())\n",
    "num_classes_train = len(y_train[1])\n",
    "\n",
    "# X_train = X_train.values.reshape(num_samples_train, max_seq_length, num_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = flat_X(X_train)\n",
    "# X_test = flat_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "La entrada son las coordenadas de las manos. Cada video cuenta con n cantidad de filas, 84 columnas (21 columnas por cada coordenada y por ambas manos).\n",
    "La salida es la frase. La frase se representa por un entero que da el one hot encoder.\n",
    "\n",
    "Se usa convoluciones para resaltar las caracteristicas en la entrada. Debido a que la entrada son coordenadas normalizadas de un video, se supone que funciona igual que si la entrada fuera una imagen. Estas redes extraen caracteristicas de forma automatica para clasificar objetos luego. Al buscar patrones, se espera que pueda predecir un video que ya ha sido entrenado previamente.\n",
    "\n",
    "Se reduce el tamaño de la entrada haciendo uso de max pooling y flatten.\n",
    "\n",
    "Se hace uso de Dense para conectar entradas con salidas.\n",
    "\n",
    "Se hace uso de Dropout para evitar el sobreajuste.\n",
    "\n",
    "Relu elimina negativos. \n",
    "Sigmoid nos ayuda a obtener la probabilidad de que un ejemplo pertenezca a la clase positiva.\n",
    "Softmax hace clasificacion multiclase (en nuestro caso las palabras a predecir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length, num_features_train)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(num_classes_train, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add input layer with appropriate input shape (84 features)\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, activation='relu', input_shape=(len(get_needed_cols()),)))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# # Output layer (adjust units according to your task)\n",
    "# model.add(Dense(num_classes_train, activation='softmax'))  # For classification, or 'linear' for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input layer with appropriate input shape (84 features)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(len(get_needed_cols()),)))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "\n",
    "# Output layer (adjust units according to your task)\n",
    "model.add(Dense(num_classes_train, activation='softmax'))  # For classification, or 'linear' for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=300, batch_size=8)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Find the most likely prediction for each sample\n",
    "most_likely_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = label_encoder.inverse_transform(most_likely_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels = train_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(predicted_labels)):\n",
    "    if (predicted_labels[i] == expected_labels[i]):\n",
    "        correct += 1\n",
    "        print(\"Correctamente predicha: \", predicted_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correct >> \", correct)\n",
    "print(\"Ratio >> \", str(correct/len(test_data.target.unique())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
