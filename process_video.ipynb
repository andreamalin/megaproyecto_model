{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/bin/ffmpeg\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import glob, os\n",
    "import numpy as np\n",
    "initial_dir = os.getcwd()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "frames = []\n",
    "ids_without_required_hands = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 30 # Frames per video\n",
    "num_samples = 1 # One video processed\n",
    "num_features = 84 # 21 rows x, 21 rows y left and right = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_X(X):\n",
    "    # Define the number of rows to be flattened\n",
    "    rows_to_flatten = max_seq_length\n",
    "\n",
    "    data_array = X.to_numpy()\n",
    "\n",
    "    # Get the number of resulting rows in the output array\n",
    "    resulting_rows = data_array.shape[0] // rows_to_flatten\n",
    "\n",
    "    # Reshape the array to have (resulting_rows, rows_to_flatten, 80) shape\n",
    "    reshaped_array = data_array[:resulting_rows * rows_to_flatten].reshape(resulting_rows, rows_to_flatten, -1)\n",
    "\n",
    "    # Flatten the reshaped array along the second axis (axis=1) to get (resulting_rows, 13600) shape\n",
    "    flattened_array = reshaped_array.reshape(resulting_rows, -1)\n",
    "\n",
    "    return flattened_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    num_hands=2,\n",
    ")\n",
    "hands = HandLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates(coordinates, target, image_height):\n",
    "    matplot_coordinates = []\n",
    "    normalized_coordinates = []\n",
    "    for x, y in coordinates:\n",
    "        y = image_height - y\n",
    "        matplot_coordinates.append([x, y])\n",
    "\n",
    "    # Find the minimum and maximum values among the coordinates\n",
    "    min_x, min_y = np.min(matplot_coordinates, axis=0)\n",
    "    max_x, max_y = np.max(matplot_coordinates, axis=0)\n",
    "\n",
    "    # Normalize the coordinates\n",
    "    normalized_coordinates = (matplot_coordinates - np.array([min_x, min_y])) / np.array([max_x - min_x, max_y - min_y])\n",
    "    \n",
    "    # Convert coordinates for plotting\n",
    "    # visualize_data(normalized_coordinates, target)\n",
    "    return normalized_coordinates\n",
    "\n",
    "def visualize_data(normalized_coordinates, target):\n",
    "    # Unzip normalized coordinates for plotting\n",
    "    normalized_x, normalized_y = zip(*normalized_coordinates)\n",
    "    \n",
    "    # Plot the normalized coordinates\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(normalized_x, normalized_y, color='blue', label=f'{target}')\n",
    "    plt.xlabel('Normalized X')\n",
    "    plt.xlabel('Normalized X')\n",
    "    plt.ylabel('Normalized Y')\n",
    "    plt.title('Normalized Coordinates Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video(video, target, sequence_id, real_path):\n",
    "    global frames\n",
    "    added_rows = 0\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "\n",
    "        name = f'{initial_dir}/test_frame.png'\n",
    "        cv2.imwrite(name, frame)\n",
    "        mp_image = mp.Image.create_from_file(name)\n",
    "        hand_landmarker_result = hands.detect(mp_image)\n",
    "\n",
    "         \n",
    "        if len(hand_landmarker_result.handedness) > 0:\n",
    "            row_data = {\n",
    "                \"sequence_id\": sequence_id,\n",
    "                \"target\": target,\n",
    "                \"file\": real_path\n",
    "            }\n",
    "            hand_sides = [\"Left\", \"Right\"]\n",
    "            for idx, landmarks in enumerate(hand_landmarker_result.hand_landmarks):\n",
    "                detected_pixels = []\n",
    "                hand_side = hand_sides[idx]\n",
    "                # Iterate through detected hand landmarks\n",
    "                for landmark_idx, landmark in enumerate(landmarks):\n",
    "                    x, y = landmark.x, landmark.y\n",
    "                    detected_pixels.append([x  * frame.shape[1], y * frame.shape[0]])\n",
    "                    # Draw circles on the frame\n",
    "                    cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "\n",
    "                    \n",
    "                detected_pixels = normalize_coordinates(detected_pixels, target, frame.shape[0])\n",
    "                for i in range(len(detected_pixels)):\n",
    "                    x, y = detected_pixels[i]\n",
    "                    row_data[f'x_{hand_side}_hand_{i}'] =  x\n",
    "                    row_data[f'y_{hand_side}_hand_{i}'] =  y\n",
    "                \n",
    "            if (len(hand_landmarker_result.handedness) == 1):\n",
    "                for i in range(21):\n",
    "                    x, y = [0, 0]\n",
    "                    row_data[f'x_{hand_sides[1]}_hand_{i}'] =  x\n",
    "                    row_data[f'y_{hand_sides[1]}_hand_{i}'] =  y\n",
    "            \n",
    "\n",
    "            added_rows += 1\n",
    "            frames.append(row_data)\n",
    "        # cv2.imshow('Hand Tracking', frame)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "        if (added_rows == 30):\n",
    "            break\n",
    "\n",
    "    if (added_rows == 0):\n",
    "        print(\"!! No hand detected in \", real_path)\n",
    "\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(filename):\n",
    "    result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                             \"format=duration\", \"-of\",\n",
    "                             \"default=noprint_wrappers=1:nokey=1\", filename],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT)\n",
    "    return float(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_30_fps(video_input_path, video_output_path):\n",
    "    duration = 1/get_length(video_input_path)\n",
    "\n",
    "    c = f'ffmpeg -loglevel 0 -y -itsscale {duration} -i \"' + video_input_path + f'\" -filter:v fps=fps=30 \"' + video_output_path + '\"'\n",
    "    subprocess.call(c, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_id = 0\n",
    "\n",
    "def extract_coordinates_from_path(path):\n",
    "    global sequence_id, initial_dir, validation_sequence_ids\n",
    "\n",
    "    output_fps_path = f'./adjusted_fps_video.mp4'\n",
    "    input_path = f'./{path}'\n",
    "    sequence_id += 1\n",
    "\n",
    "    if (\"(\" not in path):\n",
    "        name = path.split(\".\")[0]\n",
    "    else:\n",
    "        name = path[0:path.index(\"(\")].strip()\n",
    "\n",
    "\n",
    "    change_to_30_fps(video_input_path=input_path, video_output_path=output_fps_path)\n",
    "    extract_video(output_fps_path, name, sequence_id, input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_videos(df):\n",
    "    # Create a new DataFrame to store the filled rows\n",
    "    filled_df = pd.DataFrame()\n",
    "    target = []\n",
    "\n",
    "\n",
    "    # Iterate over each group and fill remaining rows with zero\n",
    "    for _, group in df.groupby('sequence_id'):\n",
    "        remaining_rows = max_seq_length - len(group)\n",
    "        zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "        zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "        zeros_df['target'] = group['target'].unique()[0]\n",
    "        group = pd.concat([group, zeros_df])\n",
    "    \n",
    "        # filled_df = filled_df.append(group)\n",
    "        filled_df = pd.concat([filled_df, group])\n",
    "        target.append(group[\"target\"].unique()[0])\n",
    "        \n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    # load\n",
    "    with open(f'{model_name}.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "svm_model = load_model(\"svm\")\n",
    "cnn_model = load_model(\"cnn\")\n",
    "tree_model = load_model(\"tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_extract = \"Hello.mp4\"\n",
    "extract_coordinates_from_path(path_to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(frames)\n",
    "df['sequence_id'] = df['sequence_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data, target = padding_videos(df)\n",
    "del padded_data[\"sequence_id\"] \n",
    "del padded_data[\"target\"] \n",
    "del padded_data[\"file\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the label encoder\n",
    "label_encoder = load_model('label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_cnn = padded_data.values.reshape(num_samples, max_seq_length, num_features)\n",
    "X_val = flat_X(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cnn = cnn_model.predict(X_val_cnn)\n",
    "predicted_tree = tree_model.predict(X_val)\n",
    "predicted_svm = svm_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_predictions = np.argmax(predicted_cnn, axis=1)\n",
    "predicted_cnn = label_encoder.inverse_transform(most_likely_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Resultados----\")\n",
    "print(f'CNN: {predicted_cnn}')\n",
    "print(f'TREE: {predicted_tree}')\n",
    "print(f'CNN: {predicted_cnn}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
