{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"validation.csv\")\n",
    "char_to_pred = json.load(open(\"data/character_to_prediction_index.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target\n",
       "0            1  bathroom\n",
       "1            1  bathroom\n",
       "2            1  bathroom\n",
       "3            1  bathroom\n",
       "4            1  bathroom"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train data--------------------\n",
      "Cantidad de filas : 7926\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Train data--------------------\")\n",
    "print(f\"Cantidad de filas : {train_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {train_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation data--------------------\n",
      "Cantidad de filas : 547\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Validation data--------------------\")\n",
    "print(f\"Cantidad de filas : {test_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {test_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (list(train_data.target.unique()) != list(test_data.target.unique())):\n",
    "    raise ValueError(\"Error between target and train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7926.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>189.509084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>111.681925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>385.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_id\n",
       "count  7926.000000\n",
       "mean    189.509084\n",
       "std     111.681925\n",
       "min       1.000000\n",
       "25%      88.000000\n",
       "50%     190.000000\n",
       "75%     283.000000\n",
       "max     385.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein Distance\n",
    "* Ref: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/#:~:text=The%20Levenshtein%20distance%20is%20a,transform%20one%20word%20into%20another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDistances(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levenshteinDistanceDP(\"kelm\", \"hello\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo se obtienen 20 indices de las coordenadas x y y, ya que son las unicas que han sido altamente entrenadas del modelo mediapipe de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_cols():\n",
    "    cols = []\n",
    "\n",
    "    for i in range(21):\n",
    "        cols.append(f'x_Right_hand_{i}')\n",
    "        cols.append(f'y_Right_hand_{i}')\n",
    "        cols.append(f'x_Left_hand_{i}')\n",
    "        cols.append(f'y_Left_hand_{i}')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df_test = df[df['sequence_id'].isin(test_data['sequence_id'])]\n",
    "df_train = df[df['sequence_id'].isin(train_data['sequence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "      <th>x_Left_hand_0</th>\n",
       "      <th>y_Left_hand_0</th>\n",
       "      <th>x_Left_hand_1</th>\n",
       "      <th>y_Left_hand_1</th>\n",
       "      <th>x_Left_hand_2</th>\n",
       "      <th>y_Left_hand_2</th>\n",
       "      <th>x_Left_hand_3</th>\n",
       "      <th>y_Left_hand_3</th>\n",
       "      <th>...</th>\n",
       "      <th>x_Right_hand_16</th>\n",
       "      <th>y_Right_hand_16</th>\n",
       "      <th>x_Right_hand_17</th>\n",
       "      <th>y_Right_hand_17</th>\n",
       "      <th>x_Right_hand_18</th>\n",
       "      <th>y_Right_hand_18</th>\n",
       "      <th>x_Right_hand_19</th>\n",
       "      <th>y_Right_hand_19</th>\n",
       "      <th>x_Right_hand_20</th>\n",
       "      <th>y_Right_hand_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.266263</td>\n",
       "      <td>0.473249</td>\n",
       "      <td>0.291757</td>\n",
       "      <td>0.440494</td>\n",
       "      <td>0.306219</td>\n",
       "      <td>0.404748</td>\n",
       "      <td>0.309409</td>\n",
       "      <td>0.371156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.261615</td>\n",
       "      <td>0.447170</td>\n",
       "      <td>0.284930</td>\n",
       "      <td>0.408778</td>\n",
       "      <td>0.293976</td>\n",
       "      <td>0.367232</td>\n",
       "      <td>0.291804</td>\n",
       "      <td>0.332398</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.261583</td>\n",
       "      <td>0.431127</td>\n",
       "      <td>0.278761</td>\n",
       "      <td>0.387111</td>\n",
       "      <td>0.281090</td>\n",
       "      <td>0.341194</td>\n",
       "      <td>0.276046</td>\n",
       "      <td>0.306308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.263054</td>\n",
       "      <td>0.418766</td>\n",
       "      <td>0.274931</td>\n",
       "      <td>0.371834</td>\n",
       "      <td>0.273662</td>\n",
       "      <td>0.329738</td>\n",
       "      <td>0.264274</td>\n",
       "      <td>0.300696</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.274704</td>\n",
       "      <td>0.416674</td>\n",
       "      <td>0.273656</td>\n",
       "      <td>0.368680</td>\n",
       "      <td>0.260158</td>\n",
       "      <td>0.332655</td>\n",
       "      <td>0.246035</td>\n",
       "      <td>0.309348</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target  x_Left_hand_0  y_Left_hand_0  x_Left_hand_1  \\\n",
       "0            1  bathroom       0.266263       0.473249       0.291757   \n",
       "1            1  bathroom       0.261615       0.447170       0.284930   \n",
       "2            1  bathroom       0.261583       0.431127       0.278761   \n",
       "3            1  bathroom       0.263054       0.418766       0.274931   \n",
       "4            1  bathroom       0.274704       0.416674       0.273656   \n",
       "\n",
       "   y_Left_hand_1  x_Left_hand_2  y_Left_hand_2  x_Left_hand_3  y_Left_hand_3  \\\n",
       "0       0.440494       0.306219       0.404748       0.309409       0.371156   \n",
       "1       0.408778       0.293976       0.367232       0.291804       0.332398   \n",
       "2       0.387111       0.281090       0.341194       0.276046       0.306308   \n",
       "3       0.371834       0.273662       0.329738       0.264274       0.300696   \n",
       "4       0.368680       0.260158       0.332655       0.246035       0.309348   \n",
       "\n",
       "   ...  x_Right_hand_16  y_Right_hand_16  x_Right_hand_17  y_Right_hand_17  \\\n",
       "0  ...              NaN              NaN              NaN              NaN   \n",
       "1  ...              NaN              NaN              NaN              NaN   \n",
       "2  ...              NaN              NaN              NaN              NaN   \n",
       "3  ...              NaN              NaN              NaN              NaN   \n",
       "4  ...              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   x_Right_hand_18  y_Right_hand_18  x_Right_hand_19  y_Right_hand_19  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   x_Right_hand_20  y_Right_hand_20  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8473\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_test) == len(test_data))\n",
    "print(len(df_train) == len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the lengths of the video sequences\n",
    "video_lengths = df.groupby('sequence_id').size()\n",
    "max_seq_length = video_lengths.max()\n",
    "# max_seq_length = 30\n",
    "# Plot the histogram\n",
    "plt.hist(video_lengths, bins=30)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Video Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Video Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a one-hot encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_videos(df):\n",
    "    # Create a new DataFrame to store the filled rows\n",
    "    filled_df = pd.DataFrame()\n",
    "    target = []\n",
    "\n",
    "\n",
    "    # Iterate over each group and fill remaining rows with zero\n",
    "    for _, group in df.groupby('sequence_id'):\n",
    "        remaining_rows = max_seq_length - len(group)\n",
    "        zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "        zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "        zeros_df['target'] = group['target'].unique()[0]\n",
    "        group = pd.concat([group, zeros_df])\n",
    "    \n",
    "        filled_df = filled_df.append(group)\n",
    "        target.append(group[\"target\"].unique()[0])\n",
    "        \n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df, target\n",
    "\n",
    "def padding_labels(target):\n",
    "    integer_encoded = label_encoder.fit_transform(target)\n",
    "    integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "\n",
    "    # Encode the word \"Hello\"\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)  # sparse=False to get a numpy array as output\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, target = padding_videos(df_train)\n",
    "y_train = padding_labels(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800 360\n"
     ]
    }
   ],
   "source": [
    "\n",
    "del X_train[\"sequence_id\"] \n",
    "del X_train[\"target\"] \n",
    "\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 25\n"
     ]
    }
   ],
   "source": [
    "X_test, target = padding_videos(df_test)\n",
    "y_test = padding_labels(target)\n",
    "del X_test[\"sequence_id\"] \n",
    "del X_test[\"target\"] \n",
    "\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train) + len(y_test) == len(df[\"sequence_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_X(X):\n",
    "    # Define the number of rows to be flattened\n",
    "    rows_to_flatten = max_seq_length\n",
    "\n",
    "    data_array = X.to_numpy()\n",
    "\n",
    "    # Get the number of resulting rows in the output array\n",
    "    resulting_rows = data_array.shape[0] // rows_to_flatten\n",
    "\n",
    "    # Reshape the array to have (resulting_rows, rows_to_flatten, 80) shape\n",
    "    reshaped_array = data_array[:resulting_rows * rows_to_flatten].reshape(resulting_rows, rows_to_flatten, -1)\n",
    "\n",
    "    # Flatten the reshaped array along the second axis (axis=1) to get (resulting_rows, 13600) shape\n",
    "    flattened_array = reshaped_array.reshape(resulting_rows, -1)\n",
    "\n",
    "    return flattened_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_size =  num_classes * num_timesteps * num_features\n",
    "# actual_size = X.iloc[:, :num_features].values.size\n",
    "# if expected_size != actual_size:\n",
    "#     raise ValueError(\"The total number of elements in the DataFrame does not match the expected size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = int(len(X_test)/max_seq_length)\n",
    "num_features = len(get_needed_cols())\n",
    "num_classes = len(y_test[1])\n",
    "\n",
    "X_test = X_test.values.reshape(num_samples, max_seq_length, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10800"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_train = int(len(X_train)/max_seq_length)\n",
    "num_features_train = len(get_needed_cols())\n",
    "num_classes_train = len(y_train[1])\n",
    "\n",
    "X_train = X_train.values.reshape(num_samples_train, max_seq_length, num_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = flat_X(X_train)\n",
    "# X_test = flat_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (360, 30, 84) (360, 25)\n",
      "Test: (25, 30, 84) (25, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "La entrada son las coordenadas de las manos. Cada video cuenta con n cantidad de filas, 84 columnas (21 columnas por cada coordenada y por ambas manos).\n",
    "La salida es la frase. La frase se representa por un entero que da el one hot encoder.\n",
    "\n",
    "Se usa convoluciones para resaltar las caracteristicas en la entrada. Debido a que la entrada son coordenadas normalizadas de un video, se supone que funciona igual que si la entrada fuera una imagen. Estas redes extraen caracteristicas de forma automatica para clasificar objetos luego. Al buscar patrones, se espera que pueda predecir un video que ya ha sido entrenado previamente.\n",
    "\n",
    "Se reduce el tamaño de la entrada haciendo uso de max pooling y flatten.\n",
    "\n",
    "Se hace uso de Dense para conectar entradas con salidas.\n",
    "\n",
    "Se hace uso de Dropout para evitar el sobreajuste.\n",
    "\n",
    "Relu elimina negativos. \n",
    "Sigmoid nos ayuda a obtener la probabilidad de que un ejemplo pertenezca a la clase positiva.\n",
    "Softmax hace clasificacion multiclase (en nuestro caso las palabras a predecir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length, num_features_train)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(num_classes_train, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), strides=(1, 1), input_shape=(max_seq_length, num_features_train, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Convolution2D(128, (3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes_train, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 15ms/step - loss: 3.1922 - accuracy: 0.0556\n",
      "Epoch 2/40\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 2.9329 - accuracy: 0.1139\n",
      "Epoch 3/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 2.7420 - accuracy: 0.1222\n",
      "Epoch 4/40\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 2.6446 - accuracy: 0.1139\n",
      "Epoch 5/40\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 2.5084 - accuracy: 0.1833\n",
      "Epoch 6/40\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 2.4624 - accuracy: 0.2278\n",
      "Epoch 7/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 2.2610 - accuracy: 0.2833\n",
      "Epoch 8/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 2.0608 - accuracy: 0.3417\n",
      "Epoch 9/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 1.8958 - accuracy: 0.3722\n",
      "Epoch 10/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 1.6916 - accuracy: 0.4528\n",
      "Epoch 11/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 1.5880 - accuracy: 0.4472\n",
      "Epoch 12/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 1.4142 - accuracy: 0.5500\n",
      "Epoch 13/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 1.3137 - accuracy: 0.5500\n",
      "Epoch 14/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 1.1211 - accuracy: 0.6361\n",
      "Epoch 15/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 1.1845 - accuracy: 0.6250\n",
      "Epoch 16/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 1.0634 - accuracy: 0.6389\n",
      "Epoch 17/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.8176 - accuracy: 0.7250\n",
      "Epoch 18/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.8448 - accuracy: 0.7111\n",
      "Epoch 19/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.7625 - accuracy: 0.7472\n",
      "Epoch 20/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.6905 - accuracy: 0.7806\n",
      "Epoch 21/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.6706 - accuracy: 0.7806\n",
      "Epoch 22/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.5325 - accuracy: 0.8278\n",
      "Epoch 23/40\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4573 - accuracy: 0.8472\n",
      "Epoch 24/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.4254 - accuracy: 0.8500\n",
      "Epoch 25/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.4704 - accuracy: 0.8500\n",
      "Epoch 26/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3980 - accuracy: 0.8611\n",
      "Epoch 27/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3509 - accuracy: 0.8778\n",
      "Epoch 28/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3497 - accuracy: 0.8556\n",
      "Epoch 29/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3113 - accuracy: 0.9056\n",
      "Epoch 30/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2823 - accuracy: 0.8861\n",
      "Epoch 31/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3569 - accuracy: 0.8806\n",
      "Epoch 32/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3198 - accuracy: 0.8944\n",
      "Epoch 33/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2790 - accuracy: 0.8972\n",
      "Epoch 34/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2514 - accuracy: 0.9222\n",
      "Epoch 35/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2061 - accuracy: 0.9361\n",
      "Epoch 36/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2168 - accuracy: 0.9333\n",
      "Epoch 37/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1911 - accuracy: 0.9472\n",
      "Epoch 38/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1873 - accuracy: 0.9472\n",
      "Epoch 39/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1983 - accuracy: 0.9222\n",
      "Epoch 40/40\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2090 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.3631 - accuracy: 0.7600\n",
      "Test accuracy: 0.7599999904632568\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=40, batch_size=8)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Find the most likely prediction for each sample\n",
    "most_likely_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  0,  4,  5,  6, 14, 19,  6, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21,  6,  2, 24], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = label_encoder.inverse_transform(most_likely_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels = train_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctamente predicha:  bathroom\n",
      "Correctamente predicha:  cat\n",
      "Correctamente predicha:  dog\n",
      "Correctamente predicha:  father\n",
      "Correctamente predicha:  fine\n",
      "Correctamente predicha:  finish\n",
      "Correctamente predicha:  learn\n",
      "Correctamente predicha:  like\n",
      "Correctamente predicha:  me\n",
      "Correctamente predicha:  milk\n",
      "Correctamente predicha:  more\n",
      "Correctamente predicha:  mother\n",
      "Correctamente predicha:  no\n",
      "Correctamente predicha:  please\n",
      "Correctamente predicha:  repeat\n",
      "Correctamente predicha:  see you later\n",
      "Correctamente predicha:  sign\n",
      "Correctamente predicha:  thank you\n",
      "Correctamente predicha:  yes\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(predicted_labels)):\n",
    "    if (predicted_labels[i] == expected_labels[i]):\n",
    "        correct += 1\n",
    "        print(\"Correctamente predicha: \", predicted_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct >>  19\n",
      "Ratio >>  0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct >> \", correct)\n",
    "print(\"Ratio >> \", str(correct/len(test_data.target.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length,num_features)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = max_seq_length * 80\n",
    "# num_timesteps = max_seq_length * num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = torch.from_numpy(X_train).float()\n",
    "# X_test = torch.from_numpy(X_test).float()\n",
    "# y_train = torch.from_numpy(y_train).float()\n",
    "# y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ASLModel(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(ASLModel, self).__init__()\n",
    "#         # RuntimeError: mat1 and mat2 shapes cannot be multiplied (6912x84 and 108x2048)\n",
    "#         # (6912x84 and 83x2048)\n",
    "\n",
    "#         self.linear1 = nn.Linear(input_size, 2048)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(2048, 1024)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.linear3 = nn.Linear(1024, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x = self.linear1(x)\n",
    "#         # x = self.relu1(x)\n",
    "#         # x = self.linear2(x)\n",
    "#         # x = self.relu2(x)\n",
    "#         # x = self.linear3(x)\n",
    "#         # print(x.shape)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Initialization\n",
    "# model = ASLModel(input_size=X_train.shape[1], output_size=y_train.shape[1]).to(device)\n",
    "# # Optimization Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preparation\n",
    "# train_data = TensorDataset(X_train, y_train)\n",
    "# test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# # DataLoader\n",
    "# BATCH_SIZE = 16\n",
    "# train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reverse the JSON dictionary\n",
    "# pred_to_char = {value: key for key, value in char_to_pred.items()}\n",
    "# def reverse_to_char(data):\n",
    "#     phrase = \"\"\n",
    "#     for i in data:\n",
    "#         phrase += str(pred_to_char.get(int(i.item())) if int(i.item()) in pred_to_char else \"_\")\n",
    "    \n",
    "#     return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RuntimeError: The size of tensor a (108) must match the size of tensor b (64) at non-singleton dimension \n",
    "# for inputs, targets in train_loader:\n",
    "#     print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 5\n",
    "# loss_fn = nn.SmoothL1Loss() \n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     train_correct = 0\n",
    "\n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # labels = labels.long()\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Calculate the loss\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "#         # Accumulate the loss\n",
    "#         train_loss += loss.item() * inputs.size(0)\n",
    "#         # Accumulate the total number of samples\n",
    "#         train_correct += inputs.size(0)\n",
    "\n",
    "#     train_loss = train_loss / train_correct\n",
    "#     train_accuracy = train_correct / len(train_data)\n",
    "\n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     test_correct = 0\n",
    "#     levenshtein_distance = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             # labels = labels.long()\n",
    "\n",
    "#             print(\"input\")\n",
    "#             print(inputs)\n",
    "#             outputs = model(inputs)     \n",
    "#             print(outputs)\n",
    "#             # Get the predicted labels\n",
    "#             _, predicted = torch.max(outputs.data, dim=1)\n",
    "#             # Calculate the loss\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             # Accumulate the loss\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             # Accumulate the total number of samples\n",
    "#             test_correct += inputs.size(0)\n",
    "\n",
    "#             print(predicted.size())\n",
    "#             outputs_array = outputs.detach().cpu().numpy()\n",
    "#             targets_array = labels.detach().cpu().numpy()\n",
    "#             # Convert predictions and targets to letter sequences\n",
    "#             pred_labels = [[pred_to_char[int(label)] for label in output if int(label) in pred_to_char ] if len(output) > 0 else [] for output in outputs_array.round()]\n",
    "#             target_labels = [[pred_to_char[label] for label in target if int(label) in pred_to_char  ] if len(target) > 0 else [] for target in targets_array.round()]\n",
    "\n",
    "#             print(\"Predicted: \", pred_labels)\n",
    "#             print(\"Expected: \", target_labels)\n",
    "#             break\n",
    "\n",
    "#             # # Calculate Levenshtein distance\n",
    "#             # levenshtein_distance += calculate_levenshtein_distance(pred_labels, target_labels)\n",
    "            \n",
    "#     # test_loss = test_loss / test_correct\n",
    "#     # test_accuracy = test_correct / len(test_data)\n",
    "#     # average_levenshtein_distance = levenshtein_distance / len(test_data)\n",
    "\n",
    "#     # Print epoch results\n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "#     # print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n",
    "#     # print(f\"Average Levenshtein Distance: {average_levenshtein_distance:.4f}\")\n",
    "#     print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
