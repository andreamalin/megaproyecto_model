{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "metadata = pd.read_csv(\"data/supplemental_metadata.csv\")\n",
    "char_to_pred = json.load(open(\"data/character_to_prediction_index.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816796431</td>\n",
       "      <td>217</td>\n",
       "      <td>3 creekhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816825349</td>\n",
       "      <td>107</td>\n",
       "      <td>scales/kuhaylah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816909464</td>\n",
       "      <td>1</td>\n",
       "      <td>1383 william lanier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816967051</td>\n",
       "      <td>63</td>\n",
       "      <td>988 franklin lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1817123330</td>\n",
       "      <td>89</td>\n",
       "      <td>6920 northeast 661st road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path  file_id  sequence_id  participant_id  \\\n",
       "0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n",
       "1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n",
       "2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n",
       "3  train_landmarks/5414471.parquet  5414471   1816967051              63   \n",
       "4  train_landmarks/5414471.parquet  5414471   1817123330              89   \n",
       "\n",
       "                      phrase  \n",
       "0               3 creekhouse  \n",
       "1            scales/kuhaylah  \n",
       "2        1383 william lanier  \n",
       "3          988 franklin lane  \n",
       "4  6920 northeast 661st road  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train data--------------------\n",
      "Cantidad de filas : 67208\n",
      "Cantidad de participantes : 94\n",
      "Cantidad de frases unicas : 46478\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Train data--------------------\")\n",
    "print(f\"Cantidad de filas : {train_data.shape[0]}\")\n",
    "print(f\"Cantidad de participantes : {train_data.participant_id.nunique()}\")\n",
    "print(f\"Cantidad de frases unicas : {train_data.phrase.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Metadata--------------------\n",
      "Cantidad de filas : 52958\n",
      "Cantidad de participantes : 72\n",
      "Cantidad de frases unicas : 508\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Metadata--------------------\")\n",
    "print(f\"Cantidad de filas : {metadata.shape[0]}\")\n",
    "print(f\"Cantidad de participantes : {metadata.participant_id.nunique()}\")\n",
    "print(f\"Cantidad de frases unicas : {metadata.phrase.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.720800e+04</td>\n",
       "      <td>6.720800e+04</td>\n",
       "      <td>67208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.094448e+09</td>\n",
       "      <td>1.072696e+09</td>\n",
       "      <td>119.758154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.395616e+08</td>\n",
       "      <td>6.177372e+08</td>\n",
       "      <td>74.330468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.414471e+06</td>\n",
       "      <td>7.109500e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.277082e+08</td>\n",
       "      <td>5.376519e+08</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.099408e+09</td>\n",
       "      <td>1.074387e+09</td>\n",
       "      <td>113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.662743e+09</td>\n",
       "      <td>1.605592e+09</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.118949e+09</td>\n",
       "      <td>2.147465e+09</td>\n",
       "      <td>254.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_id   sequence_id  participant_id\n",
       "count  6.720800e+04  6.720800e+04    67208.000000\n",
       "mean   1.094448e+09  1.072696e+09      119.758154\n",
       "std    6.395616e+08  6.177372e+08       74.330468\n",
       "min    5.414471e+06  7.109500e+04        0.000000\n",
       "25%    5.277082e+08  5.376519e+08       63.000000\n",
       "50%    1.099408e+09  1.074387e+09      113.000000\n",
       "75%    1.662743e+09  1.605592e+09      178.000000\n",
       "max    2.118949e+09  2.147465e+09      254.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein Distance\n",
    "* Ref: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/#:~:text=The%20Levenshtein%20distance%20is%20a,transform%20one%20word%20into%20another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDistances(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levenshteinDistanceDP(\"kelm\", \"hello\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo se obtienen 20 indices de las coordenadas x y y, ya que son las unicas que han sido altamente entrenadas del modelo mediapipe de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_cols():\n",
    "    cols = []\n",
    "\n",
    "    for i in range(20):\n",
    "        cols.append(f'x_right_hand_{i}')\n",
    "        cols.append(f'y_right_hand_{i}')\n",
    "        cols.append(f'x_left_hand_{i}')\n",
    "        cols.append(f'y_left_hand_{i}')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = get_needed_cols()\n",
    "sample = pd.read_parquet(\"data/train_landmarks/1019715464.parquet\", columns=selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_right_hand_0</th>\n",
       "      <th>y_right_hand_0</th>\n",
       "      <th>x_left_hand_0</th>\n",
       "      <th>y_left_hand_0</th>\n",
       "      <th>x_right_hand_1</th>\n",
       "      <th>y_right_hand_1</th>\n",
       "      <th>x_left_hand_1</th>\n",
       "      <th>y_left_hand_1</th>\n",
       "      <th>x_right_hand_2</th>\n",
       "      <th>y_right_hand_2</th>\n",
       "      <th>...</th>\n",
       "      <th>x_left_hand_17</th>\n",
       "      <th>y_left_hand_17</th>\n",
       "      <th>x_right_hand_18</th>\n",
       "      <th>y_right_hand_18</th>\n",
       "      <th>x_left_hand_18</th>\n",
       "      <th>y_left_hand_18</th>\n",
       "      <th>x_right_hand_19</th>\n",
       "      <th>y_right_hand_19</th>\n",
       "      <th>x_left_hand_19</th>\n",
       "      <th>y_left_hand_19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1975433633</th>\n",
       "      <td>0.223376</td>\n",
       "      <td>0.755344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314379</td>\n",
       "      <td>0.755479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381249</td>\n",
       "      <td>0.726833</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105947</td>\n",
       "      <td>0.612873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093977</td>\n",
       "      <td>0.584119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975433633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975433633</th>\n",
       "      <td>0.229610</td>\n",
       "      <td>0.763030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323558</td>\n",
       "      <td>0.757111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391224</td>\n",
       "      <td>0.726754</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107829</td>\n",
       "      <td>0.601616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098407</td>\n",
       "      <td>0.567502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975433633</th>\n",
       "      <td>0.233477</td>\n",
       "      <td>0.764909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.324557</td>\n",
       "      <td>0.758571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.396712</td>\n",
       "      <td>0.725978</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.112081</td>\n",
       "      <td>0.599290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>0.565760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975433633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_right_hand_0  y_right_hand_0  x_left_hand_0  y_left_hand_0  \\\n",
       "sequence_id                                                                 \n",
       "1975433633         0.223376        0.755344            NaN            NaN   \n",
       "1975433633              NaN             NaN            NaN            NaN   \n",
       "1975433633         0.229610        0.763030            NaN            NaN   \n",
       "1975433633         0.233477        0.764909            NaN            NaN   \n",
       "1975433633              NaN             NaN            NaN            NaN   \n",
       "\n",
       "             x_right_hand_1  y_right_hand_1  x_left_hand_1  y_left_hand_1  \\\n",
       "sequence_id                                                                 \n",
       "1975433633         0.314379        0.755479            NaN            NaN   \n",
       "1975433633              NaN             NaN            NaN            NaN   \n",
       "1975433633         0.323558        0.757111            NaN            NaN   \n",
       "1975433633         0.324557        0.758571            NaN            NaN   \n",
       "1975433633              NaN             NaN            NaN            NaN   \n",
       "\n",
       "             x_right_hand_2  y_right_hand_2  ...  x_left_hand_17  \\\n",
       "sequence_id                                  ...                   \n",
       "1975433633         0.381249        0.726833  ...             NaN   \n",
       "1975433633              NaN             NaN  ...             NaN   \n",
       "1975433633         0.391224        0.726754  ...             NaN   \n",
       "1975433633         0.396712        0.725978  ...             NaN   \n",
       "1975433633              NaN             NaN  ...             NaN   \n",
       "\n",
       "             y_left_hand_17  x_right_hand_18  y_right_hand_18  x_left_hand_18  \\\n",
       "sequence_id                                                                     \n",
       "1975433633              NaN         0.105947         0.612873             NaN   \n",
       "1975433633              NaN              NaN              NaN             NaN   \n",
       "1975433633              NaN         0.107829         0.601616             NaN   \n",
       "1975433633              NaN         0.112081         0.599290             NaN   \n",
       "1975433633              NaN              NaN              NaN             NaN   \n",
       "\n",
       "             y_left_hand_18  x_right_hand_19  y_right_hand_19  x_left_hand_19  \\\n",
       "sequence_id                                                                     \n",
       "1975433633              NaN         0.093977         0.584119             NaN   \n",
       "1975433633              NaN              NaN              NaN             NaN   \n",
       "1975433633              NaN         0.098407         0.567502             NaN   \n",
       "1975433633              NaN         0.102222         0.565760             NaN   \n",
       "1975433633              NaN              NaN              NaN             NaN   \n",
       "\n",
       "             y_left_hand_19  \n",
       "sequence_id                  \n",
       "1975433633              NaN  \n",
       "1975433633              NaN  \n",
       "1975433633              NaN  \n",
       "1975433633              NaN  \n",
       "1975433633              NaN  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1975433633, 1975473601, 1975502450, 1975521182, 1975541698,\n",
       "            1975562925, 1975572309, 1975589819, 1975645112, 1975681715,\n",
       "            ...\n",
       "             228089325,  228121127,  228161302,  228193945,  228249271,\n",
       "             228257007,  228314839,  228354603,  228355919,  228449435],\n",
       "           dtype='int64', name='sequence_id', length=1998)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.read_parquet('./data/train_landmarks/1019715464.parquet', columns=selected_columns)\n",
    "\n",
    "parquets = [\"128822441.parquet\"]\n",
    "# parquets = [\"128822441.parquet\", \"149822653.parquet\", \"152029243.parquet\", \"169560558.parquet\",\n",
    "#             \"175396851.parquet\", \"1019715464.parquet\", \"1021040628.parquet\", \"1098899348.parquet\"]\n",
    "for parquet in parquets:\n",
    "    s2 = pd.read_parquet(f'./data/train_landmarks/{parquet}', columns=selected_columns)\n",
    "    # Concatenate the dataframes\n",
    "    s = pd.concat([s, s2])\n",
    "\n",
    "\n",
    "s.index.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318961"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.reset_index().rename(columns={'index': 'sequence_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = pd.read_csv(\"data/train.csv\", usecols=[\"sequence_id\", \"phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67208"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcuElEQVR4nO3deZwdZZ3v8c+XfQmyJWZCwtCgAYxXDdBguKCDIosgBBQwDEtAxjgjMHAd5xq4jIbXDHeCL4XB6wwSFgkgSwxbBBwJCDJwEUjClrBIgHCTEJIGDSGArL/7Rz2nUjSnu08nXedUur/v1+u8uuqp7XfOSc6vnqeqnkcRgZmZGcA6rQ7AzMyqw0nBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgvSZpnqR9Wh1HK0k6XNJCSSsl7bIa26+UtEMXy06QdO+aR1lNku6W9DetjsPqc1KwD5C0QNKXOpV94EcqIj4ZEXf3sJ82SSFpvZJCbbUfAadExKCIeLi4QNJTkr7ReQNJp0maBZC2e65JsdaOP0nSVf39mLZmnBRsrVSBZLMdMK+LZVOB4+uUH5eWmVWWk4L1WrE2IWkPSbMkrZC0VNJ5abV70t/lqalkT0nrSDpL0guSlkm6QtLmhf0en5a9IumfOh1nkqTpkq6StAI4IR37fknLJS2R9FNJGxT2F5K+LekZSa9J+mdJH5P0f1O804rrd3qPdWOVtKGklcC6wKOSnq2z+ZXA3pK2K+xvFPBp4JpCbB9P01tLmpFiehD4WKdYdpY0U9IfJT0t6ajCss1TbB0p1rMk9fr/taQx6XNZLunRYvNgau75Z0n3pc/xdkmDC8vrfm+SDgTOBL6e/g08WjjkdvX2J2mj9B2/kmJ5SNLQ3r4fWwMR4Zdf+QtYAHypU9kJwL311gHuB45L04OAMWm6DQhgvcJ23wDmAzukdW8ArkzLRgErgb2BDciaZ94pHGdSmj+M7GRmY2A3YAywXjrek8DpheMFcDPwEeCTwFvAnen4mwNPAOO7+By6jLWw74938znOBM4qzP8rcFO97YFrgWnApsB/AxbXPu9UthA4Mb3PXYCXgVFp+RXpPW6WPoM/ACd1EdMk4Ko65cOBV4CD0me7X5ofkpbfDTwL7Jg+97uByb343q7qdLzu9vct4FfAJmSJdzfgI63+fzGQXq4pWD03pbO05ZKWA//RzbrvAB+XNDgiVkbE77tZ9xjgvIh4LiJWAmcA41JT0BHAryLi3oh4G/g+2Q9n0f0RcVNEvB8Rb0bE7Ij4fUS8GxELgIuAv+q0zQ8jYkVEzAPmAren478K/JrsR7a3sTZiKllzEenM/RjqNB1JWhf4GvD9iHg9IuZ2Wu8rwIKI+Hl6nw8D1wNHpm3HAWdExGvpM/hx7bi9cCxwW0Tclj7bmcAssiRR8/OI+ENEvEmWwEan8ka+t3q62t87wNZkCfO99B2v6OX7sTXgpGD1HBYRW9RewLe7WfcksjO+p1JV/yvdrLsN8EJh/gWys9+hadnC2oKIeIPsbLVoYXFG0o6SbpH0UmpS+t/A4E7bLC1Mv1lnftBqxNqIG4BhksYA+5Cd+d5aZ70hab/F91Y87nbAZzsl6WOAvyB7r+vXiXN4gzEWj3Fkp2PsDQwrrPNSYfoNVn1ujXxv9XS1vyuB3wDXSnpR0g8lrd+bN2NrptUX62wtFxHPAEens+GvAtMlbU39s8UXyX6Aav4SeJfsh3oJsFNtgaSNyc4YP3C4TvMXAg8DR0fEa5JOJztz7QvdxdqjiHhD0nSyC84bA9emM+nOOtJ+twWeKhyrZiHwu4jYr/OGqabwTorzicK2ixuJsdMxroyIb/ZyO+j5e+tVN8wR8Q5wNnC2pDbgNuBp4NLViM1Wg2sKtkYkHStpSES8DyxPxe+T/di9T9YmX3MN8D8kbS9pENmZ/XUR8S4wHThE0n9PF38nAerh8JsBK4CVknYG/q6P3lZPsTZqKvB1suahuncdRcR7ZLWKSZI2SRekxxdWuQXYUdJxktZPr90lfSJtOw04R9Jm6cL2d4DubgFdJ13Mrb02TOsfIukASeum8n0kjWjgPfb0vS0F2hq9+C3pC5I+lRLeCrKk934j21rfcFKwNXUgMC/dkXMBMC61978BnAPcl5okxgCXkTUP3AM8D/wZOBUgtfmfSnbRdQnZxctlZBeHu/Jd4K+B14CLgev68H11GWsv3AO8CiyKiIe6We8UsuaTl4DLgZ/XFkTEa8D+ZNcOXkzrnAtsmFY5FXgdeA64F7g6xd6Vo8mazWqvZyNiITCW7E6hDrKawz/SwO9DA9/bL9PfVyTN6Wl/ZM1i08kSwpPA78i+B2sSRXiQHauedHa+HBgZEc+3OBxrkL+3tZ9rClYZkg5JTSibkt3a+DjZ7a9WYf7e+hcnBauSsWRNJC8CI8maolyVrT5/b/2Im4/MzCznmoKZmeXW6ucUBg8eHG1tba0Ow8xsrTJ79uyXI2JIvWVrdVJoa2tj1qxZrQ7DzGytIumFrpa5+cjMzHJOCmZmlnNSMDOznJOCmZnlSksKqVOtB9MoTvMknZ3Kt5f0gKT5kq5LnWihbESr61L5A6mHRDMza6IyawpvAV+MiM+QDaBxYOoU7Vzg/Ij4OPAnsv74SX//lMrPT+uZmVkTlZYUIrMyza6fXgF8kawXRMi6Ez4sTY9lVffC04F9JfXUdbKZmfWhUq8ppL7ZHyHrSncm2bisywt90i9i1ShRw0kjOKXlr/LhQVaQNEHZQPGzOjo6ygzfzGzAKTUppDFWRwMjgD2Anftgn1Mioj0i2ocMqftAnpmZraamPNEcEcsl3QXsCWwhab1UGxjBqqEDF5MNSbgoDY6+OY2N9dpvtU2sN6Tvhy2YfHDJkZjZQFHm3UdDJG2RpjcG9iMbSekuVo2jOx64OU3PYNUwhEcAv3X3u2ZmzVVmTWEYMDWNtboOMC0ibpH0BHCtpH8hG3S9NiD3pcCVkuYDfyQbftDMzJqotKQQEY8Bu9Qpf47s+kLn8j8DR5YVj5mZ9cxPNJuZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOzXFPGU7ByedwFM+srrimYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5UpLCpK2lXSXpCckzZN0WiqfJGmxpEfS66DCNmdImi/paUkHlBWbmZnVV2bX2e8C/xARcyRtBsyWNDMtOz8iflRcWdIoYBzwSWAb4A5JO0bEeyXGaGZmBaXVFCJiSUTMSdOvAU8Cw7vZZCxwbUS8FRHPA/OBPcqKz8zMPqwp1xQktQG7AA+kolMkPSbpMklbprLhwMLCZouok0QkTZA0S9Ksjo6OMsM2MxtwSk8KkgYB1wOnR8QK4ELgY8BoYAnw497sLyKmRER7RLQPGTKkr8M1MxvQSk0KktYnSwi/iIgbACJiaUS8FxHvAxezqoloMbBtYfMRqczMzJqkzLuPBFwKPBkR5xXKhxVWOxyYm6ZnAOMkbShpe2Ak8GBZ8ZmZ2YeVeffRXsBxwOOSHkllZwJHSxoNBLAA+BZARMyTNA14guzOpZN955GZWXOVlhQi4l5AdRbd1s025wDnlBWTmZl1z080m5lZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLlTnymq2l2ibe2vC6CyYfXGIkZtZsTgot0JsfXTOzZnLzkZmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc53Hw0gvuvJzHrimoKZmeWcFMzMLFdaUpC0raS7JD0haZ6k01L5VpJmSnom/d0ylUvSTyTNl/SYpF3Lis3MzOors6bwLvAPETEKGAOcLGkUMBG4MyJGAnemeYAvAyPTawJwYYmxmZlZHaUlhYhYEhFz0vRrwJPAcGAsMDWtNhU4LE2PBa6IzO+BLSQNKys+MzP7sKZcU5DUBuwCPAAMjYgladFLwNA0PRxYWNhsUSrrvK8JkmZJmtXR0VFe0GZmA1DpSUHSIOB64PSIWFFcFhEBRG/2FxFTIqI9ItqHDBnSh5GamVmpSUHS+mQJ4RcRcUMqXlprFkp/l6XyxcC2hc1HpDIzM2uSMu8+EnAp8GREnFdYNAMYn6bHAzcXyo9PdyGNAV4tNDOZmVkTlPlE817AccDjkh5JZWcCk4Fpkk4CXgCOSstuAw4C5gNvACeWGJuZmdVRWlKIiHsBdbF43zrrB3ByWfGYmVnP/ESzmZnlGkoKkj5VdiBmZtZ6jdYU/kPSg5K+LWnzUiMyM7OWaSgpRMTngGPIbhmdLelqSfuVGpmZmTVdw9cUIuIZ4Czge8BfAT+R9JSkr5YVnJmZNVej1xQ+Lel8sv6LvggcEhGfSNPnlxifmZk1UaO3pP4f4BLgzIh4s1YYES9KOquUyMzMrOkaTQoHA29GxHsAktYBNoqINyLiytKiMzOzpmr0msIdwMaF+U1SmZmZ9SONJoWNImJlbSZNb1JOSGZm1iqNJoXXi8NjStoNeLOb9c3MbC3U6DWF04FfSnqRrD+jvwC+XlZQZmbWGg0lhYh4SNLOwE6p6OmIeKe8sMzMrBV600vq7kBb2mZXSUTEFaVEZWZmLdFQUpB0JfAx4BHgvVQcgJOCmVk/0mhNoR0YlcY8MDOzfqrRu4/mkl1cNjOzfqzRmsJg4AlJDwJv1Qoj4tBSorK1RtvEWxtab8Hkg0uOxMz6QqNJYVKZQZiZWTU0ekvq7yRtB4yMiDskbQKsW25oZmbWbI12nf1NYDpwUSoaDtxUUkxmZtYijV5oPhnYC1gB+YA7Hy0rKDMza41Gk8JbEfF2bUbSemTPKZiZWT/SaFL4naQzgY3T2My/BH5VXlhmZtYKjSaFiUAH8DjwLeA2svGazcysH2koKUTE+xFxcUQcGRFHpOlum48kXSZpmaS5hbJJkhZLeiS9DiosO0PSfElPSzpg9d+SmZmtrkb7PnqeOtcQImKHbja7HPgpH+4f6fyI+FGn/Y8CxgGfBLYB7pC0Y234TzMza47e9H1UsxFwJLBVdxtExD2S2hrc/1jg2oh4C3he0nxgD+D+Brc3M7M+0Gjz0SuF1+KI+DdgdfstOEXSY6l5actUNhxYWFhnUSozM7MmavThtV0Lr3ZJf0vvxmKouZCsC+7RwBLgx73dgaQJkmZJmtXR0bEaIZiZWVca/WEv/ni/CywAjurtwSJiaW1a0sXALWl2MbBtYdURqazePqYAUwDa29v9rISZWR9qtO+jL/TFwSQNi4glafZwsi65AWYAV0s6j+xC80jgwb44ppmZNa7Ru4++093yiDivzjbXAPsAgyUtAn4A7CNpNNmdTAvInnkgIuZJmgY8QVYTOdl3HpmZNV9v7j7aneyMHuAQsjP5Z7raICKOrlN8aTfrnwOc02A8ZmZWgkaTwghg14h4DbKH0IBbI+LYsgIzM7Pma7Sbi6HA24X5t1OZmZn1I43WFK4AHpR0Y5o/DJhaSkRmZtYyjd59dI6kXwOfS0UnRsTD5YVlZmat0GjzEcAmwIqIuABYJGn7kmIyM7MWafSJ5h8A3wPOSEXrA1eVFZSZmbVGozWFw4FDgdcBIuJFYLOygjIzs9ZoNCm8ncZPCABJm5YXkpmZtUqjSWGapIuALSR9E7gDuLi8sMzMrBV6vPtIkoDrgJ2BFcBOwPcjYmbJsZmZWZP1mBQiIiTdFhGfApwIzMz6sUabj+ZI2r3USMzMrOUafaL5s8CxkhaQ3YEkskrEp8sKzMzMmq/bpCDpLyPi/wEHNCkeMzNroZ5qCjeR9Y76gqTrI+JrTYjJzMxapKdrCipM71BmIGZm1no9JYXoYtrMzPqhnpqPPiNpBVmNYeM0DasuNH+k1OjMzKypuk0KEbFuswIxM7PW603X2WZm1s85KZiZWc5JwczMco0+0WwNaJt4a6tDMDNbI64pmJlZzjUFa4pGa1ELJh9cciRm1h3XFMzMLFdaUpB0maRlkuYWyraSNFPSM+nvlqlckn4iab6kxyTtWlZcZmbWtTJrCpcDB3YqmwjcGREjgTvTPMCXgZHpNQG4sMS4zMysC6UlhYi4B/hjp+KxwNQ0PRU4rFB+RWR+TzYW9LCyYjMzs/qafU1haEQsSdMvAUPT9HBgYWG9RansQyRNkDRL0qyOjo7yIjUzG4BadqE5IoLV6Hk1IqZERHtEtA8ZMqSEyMzMBq5mJ4WltWah9HdZKl8MbFtYb0QqMzOzJmp2UpgBjE/T44GbC+XHp7uQxgCvFpqZzMysSUp7eE3SNcA+wGBJi4AfAJOBaZJOAl4Ajkqr3wYcBMwH3gBOLCsuMzPrWmlJISKO7mLRvnXWDeDksmIxM7PG+IlmMzPLOSmYmVnOHeJZpbjjPLPWck3BzMxyTgpmZpZzUjAzs5yTgpmZ5QbshebejKfsi5pmNlC4pmBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLtWQ4TkkLgNeA94B3I6Jd0lbAdUAbsAA4KiL+1Ir4OuvN0J1mZmuzVtYUvhARoyOiPc1PBO6MiJHAnWnezMyaqCU1hS6MBfZJ01OBu4HvtSoYq7ZGa28LJh9cciRm/UuragoB3C5ptqQJqWxoRCxJ0y8BQ+ttKGmCpFmSZnV0dDQjVjOzAaNVNYW9I2KxpI8CMyU9VVwYESEp6m0YEVOAKQDt7e111zEzs9XTkppCRCxOf5cBNwJ7AEslDQNIf5e1IjYzs4Gs6UlB0qaSNqtNA/sDc4EZwPi02njg5mbHZmY20LWi+WgocKOk2vGvjoj/lPQQME3SScALwFEtiM3MbEBrelKIiOeAz9QpfwXYt9nxmJnZKn6i2czMclV6TsGsz/l5BrPecU3BzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws57uPzPBdSmY1rimYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZz30dmvdBoH0ngfpJs7eSagpmZ5ZwUzMws56RgZmY5X1MwK0lvrj/0JV/LsDXhmoKZmeWcFMzMLFe55iNJBwIXAOsCl0TE5BaHZLZW8dCitiYqlRQkrQv8O7AfsAh4SNKMiHiitZGZDVxOMgNLpZICsAcwPyKeA5B0LTAWcFIw62N9fSG8jAf7+ktCKuOmg7Lec9WSwnBgYWF+EfDZ4gqSJgAT0uxKSU+v5rEGAy+v5rbNUvUYqx4fVD/GqscHJcSoc/tyb6BzK/85Vu0z3K6rBVVLCj2KiCnAlDXdj6RZEdHeByGVpuoxVj0+qH6MVY8PHGNfqHp8RVW7+2gxsG1hfkQqMzOzJqhaUngIGClpe0kbAOOAGS2OycxswKhU81FEvCvpFOA3ZLekXhYR80o63Bo3QTVB1WOsenxQ/RirHh84xr5Q9fhyiohWx2BmZhVRteYjMzNrIScFMzPLDcikIOlASU9Lmi9pYotiuEzSMklzC2VbSZop6Zn0d8tULkk/SfE+JmnXJsS3raS7JD0haZ6k0yoY40aSHpT0aIrx7FS+vaQHUizXpZsWkLRhmp+flreVHWM67rqSHpZ0S0XjWyDpcUmPSJqVyirzPafjbiFpuqSnJD0pac+qxChpp/TZ1V4rJJ1elfh6LSIG1IvsAvazwA7ABsCjwKgWxPF5YFdgbqHsh8DEND0RODdNHwT8GhAwBnigCfENA3ZN05sBfwBGVSxGAYPS9PrAA+nY04BxqfxnwN+l6W8DP0vT44DrmvRdfwe4GrglzVctvgXA4E5llfme03GnAn+TpjcAtqhajOnY6wIvkT0cVrn4GnoPrQ6g6W8Y9gR+U5g/AzijRbG0dUoKTwPD0vQw4Ok0fRFwdL31mhjrzWR9UlUyRmATYA7ZE/AvA+t1/r7J7mrbM02vl9ZTyXGNAO4Evgjckn4IKhNfOla9pFCZ7xnYHHi+82dRpRgLx9ofuK+q8TXyGojNR/W60hjeolg6GxoRS9L0S8DQNN3SmFMzxi5kZ+KVijE1zTwCLANmktUCl0fEu3XiyGNMy18Fti45xH8D/ifwfprfumLxAQRwu6TZyrqRgWp9z9sDHcDPUzPcJZI2rViMNeOAa9J0FePr0UBMCmuFyE4hWn6/sKRBwPXA6RGxorisCjFGxHsRMZrsjHwPYOdWxlMk6SvAsoiY3epYerB3ROwKfBk4WdLniwsr8D2vR9bUemFE7AK8TtYck6tAjKRrQ4cCv+y8rArxNWogJoUqd6WxVNIwgPR3WSpvScyS1idLCL+IiBuqGGNNRCwH7iJrjtlCUu3BzGIceYxp+ebAKyWGtRdwqKQFwLVkTUgXVCg+ACJicfq7DLiRLLlW6XteBCyKiAfS/HSyJFGlGCFLqnMiYmmar1p8DRmISaHKXWnMAMan6fFk7fi18uPTXQtjgFcL1dJSSBJwKfBkRJxX0RiHSNoiTW9Mds3jSbLkcEQXMdZiPwL4bTqDK0VEnBERIyKijezf2W8j4piqxAcgaVNJm9WmydrE51Kh7zkiXgIWStopFe1L1p1+ZWJMjmZV01EtjirF15hWX9RoxYvs6v8fyNqf/1eLYrgGWAK8Q3YmdBJZ+/GdwDPAHcBWaV2RDT70LPA40N6E+PYmq+4+BjySXgdVLMZPAw+nGOcC30/lOwAPAvPJqvIbpvKN0vz8tHyHJn7f+7Dq7qPKxJdieTS95tX+P1Tpe07HHQ3MSt/1TcCWVYoR2JSsVrd5oawy8fXm5W4uzMwsNxCbj8zMrAtOCmZmlnNSMDOznJOCmZnlnBTMzCznpGD9krIeXg/oVHa6pAslHaoueseVtLKPjr9A0uC+2FcX+z9B0jbNOp4NHE4K1l9dQ/bAWNE44JqImBERk1sQU186Adimp5XMestJwfqr6cDBWjVWQRvZj+h/pbPsn6by7SXdr2w8gX8p7kDSP0p6KPV5f3ah/DuS5qbX6Y0GlJ7Avj7t8yFJe6XyScrG17hb0nOS/r6wzT8pG/vjXknXSPqupCOAduAXqf/+jdPqp0qak95LZfqAsrWLk4L1SxHxR7Kngr+cisYB0+LDT2teQNbR2qfInjAHQNL+wEiyfoBGA7tJ+ryk3YATybroHgN8U9IuDYZ1AXB+ROwOfA24pLBsZ+CAdLwfSFpfUm29z6T30Z7e23Syp3uPiYjREfFm2sfLkXVsdyHw3QZjMvuA9XpexWytVWtCujn9PanOOnuR/fACXAmcm6b3T6+H0/wgsiQxCLgxIl4HkHQD8LnCet35EjAq61YKgI+kXmgBbo2It4C3JC0j62Z5L+DmiPgz8GdJv+ph/7VOC2cDX20gHrMPcVKw/uxm4Pw03OEm0XUX1vX6ehHwrxFx0QcK07Ckq2kdYEz6kS/uE+CtQtF7rN7/zdo+Vnd7MzcfWf8VESvJeiS9jA/2Xll0H6suSB9TKP8N8I3ambyk4ZI+CvwXcJikTVKvooenskbcDpxam5E0uof17wMOUTYW9SDgK4Vlr5ENk2rWp3w2Yf3dNWRjBHS+E6nmNOBqSd9jVdfGRMTtkj4B3J/O5FcCx0bEHEmXk12vALgkIrpqOnpMUm3EtWnA3wP/Lukxsv979wB/21XgEfGQpBlkPYMuJetR89W0+HLgZ5LeJBtDwqxPuJdUswqTNCgiVkrahCyJTIiIOa2Oy/ov1xTMqm2KpFFkYy1MdUKwsrmmYGZmOV9oNjOznJOCmZnlnBTMzCznpGBmZjknBTMzy/1/neC4iqSw+YAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged = pd.merge(s, phrases, on='sequence_id')\n",
    "# Compute the lengths of the video sequences\n",
    "video_lengths = merged.groupby('sequence_id').size()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(video_lengths, bins=30)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Video Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Video Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum sequence length\n",
    "grouped = merged.groupby('sequence_id')\n",
    "max_seq_length = 170\n",
    "\n",
    "# Filter out IDs with more than 170 rows\n",
    "filtered_df = grouped.filter(lambda x: len(x) <= max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store the filled rows\n",
    "filled_df = pd.DataFrame()\n",
    "target = []\n",
    "\n",
    "\n",
    "# Iterate over each group and fill remaining rows with zero\n",
    "for _, group in filtered_df.groupby('sequence_id'):\n",
    "    remaining_rows = max_seq_length - len(group)\n",
    "    if remaining_rows > 0:\n",
    "        zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "        zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "        zeros_df['phrase'] = group['phrase'].unique()[0]\n",
    "        group = pd.concat([group, zeros_df])\n",
    "    \n",
    "    if (group[\"phrase\"].unique()[0] not in target):\n",
    "        filled_df = filled_df.append(group)\n",
    "        target.append(group[\"phrase\"].unique()[0])\n",
    "    \n",
    "filled_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{170}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(filled_df.groupby('sequence_id').size().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del filled_df[\"sequence_id\"] \n",
    "del filled_df[\"phrase\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each text in the list to numerical labels\n",
    "numerical_labels_list = []\n",
    "for text in target:\n",
    "    numerical_labels = [char_to_pred[char] for char in text]\n",
    "    numerical_labels_list.append(torch.tensor(numerical_labels))\n",
    "\n",
    "# Pad the sequences to the maximum length\n",
    "padded_labels = pad_sequence(numerical_labels_list, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = padded_labels #La variable respuesta\n",
    "X = filled_df.fillna(0) #El resto de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = max_seq_length\n",
    "num_features = len(get_needed_cols())\n",
    "num_classes = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_size =  num_classes * num_timesteps * num_features\n",
    "actual_size = X.iloc[:, :num_features].values.size\n",
    "if expected_size != actual_size:\n",
    "    raise ValueError(\"The total number of elements in the DataFrame does not match the expected size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.reshape(num_classes, num_timesteps, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 170, 80)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (846, 170, 80) torch.Size([846, 30])\n",
      "Test: (363, 170, 80) torch.Size([363, 30])\n"
     ]
    }
   ],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, sequence_length):\n",
    "        super(ASLModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        print(input)\n",
    "        batch_size = input.size(0)\n",
    "        num_rows = input.size(1)\n",
    "        num_cols = input.size(2)\n",
    "\n",
    "\n",
    "        # Aplicar la capa de embedding\n",
    "        embedded = self.embedding(input)\n",
    "        print(\"embedded\", embedded.size())\n",
    "        \n",
    "        # Reshape el embedding a (batch_size, seq_length, hidden_size)\n",
    "        embedded = embedded.view(batch_size, num_rows * num_cols, -1)\n",
    "        print(\"embedded 1 \", embedded.size())\n",
    "\n",
    "        # Pasar la secuencia de entrada a través de la GRU\n",
    "        output, _ = self.gru(embedded)\n",
    "        print(\"output 1 \", output.size())\n",
    "\n",
    "        # Obtener la última predicción de cada secuencia\n",
    "        output = output[:, -1, :]\n",
    "        # Utilizar la última salida de la GRU como entrada para la capa lineal\n",
    "        output = self.fc(output)\n",
    "        print(\"output 2\", output.size())\n",
    "\n",
    "        # # Replicar la salida para cada letra de la secuencia\n",
    "        # Apply the softmax activation function\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # print(\"output 3\", output.size())\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir los parámetros del modelo\n",
    "input_size = 59  # Número de letras posibles (0 a 27)\n",
    "hidden_size = 32  # Tamaño de la capa oculta\n",
    "output_size = 30  ## Longitud máxima de la secuencia de letras\n",
    "sequence_length = 30  # Longitud máxima de la secuencia de letras\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = ASLModel(input_size, hidden_size, output_size, sequence_length)\n",
    "\n",
    "# Optimization Setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3716, 0.7548, 0.0000,  ..., 0.6976, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3776, 0.7168, 0.0000,  ..., 0.6362, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the JSON dictionary\n",
    "pred_to_char = {value: key for key, value in char_to_pred.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_to_char(data):\n",
    "    phrase = \"\"\n",
    "    for i in data:\n",
    "        phrase += str(pred_to_char.get(int(i.item())) if int(i.item()) in pred_to_char else \"_\")\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3716, 0.7548, 0.0000,  ..., 0.6976, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3776, 0.7168, 0.0000,  ..., 0.6362, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[3715, 7548,    0,  ..., 6975,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [3776, 7168,    0,  ..., 6362,    0,    0],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]])\n",
      "tensor([[[3715, 7548,    0,  ..., 6975,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [3776, 7168,    0,  ..., 6362,    0,    0],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[2022, 6637,    0,  ..., 4859,    0,    0],\n",
      "         [2087, 6495,    0,  ..., 4661,    0,    0],\n",
      "         [2093, 6340,    0,  ..., 4525,    0,    0],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[3783, 8072,    0,  ..., 7168,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3415, 8176,    0,  ..., 7653,    0,    0],\n",
      "         [3518, 8310,    0,  ..., 7263,    0,    0],\n",
      "         [3516, 8299,    0,  ..., 7183,    0,    0],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[2782, 7062,    0,  ..., 5203,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[1662, 7986,    0,  ..., 9268,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [1504, 7339,    0,  ..., 6499,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8144\\3744239355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Pasar los datos de entrada a través del modelo y obtener las predicciones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mpredicted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8144\\3033194067.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Aplicar la capa de embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"embedded\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    158\u001b[0m         return F.embedding(\n\u001b[0;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2197\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2199\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Iterar sobre los lotes de entrenamiento\n",
    "    for batch in train_loader:\n",
    "        # Obtener los datos de entrada y las etiquetas del lote\n",
    "        inputs, labels = batch\n",
    "\n",
    "        print(inputs[0])\n",
    "        inputs = inputs * 10000\n",
    "        inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        print(inputs[0])\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        # Pasar los datos de entrada a través del modelo y obtener las predicciones\n",
    "        outputs = model(inputs)\n",
    "        predicted_indices = torch.argmax(outputs, dim=1)\n",
    "        print(outputs)\n",
    "        print(labels[0])\n",
    "\n",
    "        # Calcular la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Realizar la retropropagación y la optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Acumular la pérdida total del entrenamiento\n",
    "        train_loss += loss.item()\n",
    "        break\n",
    "\n",
    "    # Calcular la pérdida promedio del entrenamiento\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Imprimir información del entrenamiento\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {train_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
