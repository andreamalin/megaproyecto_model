{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"validation.csv\")\n",
    "char_to_pred = json.load(open(\"data/character_to_prediction_index.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target\n",
       "0            2  bathroom\n",
       "1            2  bathroom\n",
       "2            2  bathroom\n",
       "3            2  bathroom\n",
       "4            2  bathroom"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train data--------------------\n",
      "Cantidad de filas : 2100\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Train data--------------------\")\n",
    "print(f\"Cantidad de filas : {train_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {train_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation data--------------------\n",
      "Cantidad de filas : 664\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Validation data--------------------\")\n",
    "print(f\"Cantidad de filas : {test_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {test_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (list(train_data.target.unique()) != list(test_data.target.unique())):\n",
    "    raise ValueError(\"Error between target and train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.951905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.514565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_id\n",
       "count  2100.000000\n",
       "mean     54.951905\n",
       "std      30.514565\n",
       "min       2.000000\n",
       "25%      31.000000\n",
       "50%      55.000000\n",
       "75%      81.000000\n",
       "max     107.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein Distance\n",
    "* Ref: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/#:~:text=The%20Levenshtein%20distance%20is%20a,transform%20one%20word%20into%20another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDistances(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levenshteinDistanceDP(\"kelm\", \"hello\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo se obtienen 20 indices de las coordenadas x y y, ya que son las unicas que han sido altamente entrenadas del modelo mediapipe de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_cols():\n",
    "    cols = []\n",
    "\n",
    "    for i in range(21):\n",
    "        cols.append(f'x_right_hand_{i}')\n",
    "        cols.append(f'y_right_hand_{i}')\n",
    "        cols.append(f'x_left_hand_{i}')\n",
    "        cols.append(f'y_left_hand_{i}')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df_test = df[df['sequence_id'].isin(test_data['sequence_id'])]\n",
    "df_train = df[df['sequence_id'].isin(train_data['sequence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "      <th>x_right_hand_0</th>\n",
       "      <th>x_right_hand_1</th>\n",
       "      <th>x_right_hand_10</th>\n",
       "      <th>x_right_hand_11</th>\n",
       "      <th>x_right_hand_12</th>\n",
       "      <th>x_right_hand_13</th>\n",
       "      <th>x_right_hand_14</th>\n",
       "      <th>x_right_hand_15</th>\n",
       "      <th>...</th>\n",
       "      <th>y_left_hand_19</th>\n",
       "      <th>y_left_hand_2</th>\n",
       "      <th>y_left_hand_20</th>\n",
       "      <th>y_left_hand_3</th>\n",
       "      <th>y_left_hand_4</th>\n",
       "      <th>y_left_hand_5</th>\n",
       "      <th>y_left_hand_6</th>\n",
       "      <th>y_left_hand_7</th>\n",
       "      <th>y_left_hand_8</th>\n",
       "      <th>y_left_hand_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.264414</td>\n",
       "      <td>0.291182</td>\n",
       "      <td>0.288854</td>\n",
       "      <td>0.293428</td>\n",
       "      <td>0.294785</td>\n",
       "      <td>0.266834</td>\n",
       "      <td>0.274996</td>\n",
       "      <td>0.279632</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.259750</td>\n",
       "      <td>0.284009</td>\n",
       "      <td>0.269205</td>\n",
       "      <td>0.276955</td>\n",
       "      <td>0.280713</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.257347</td>\n",
       "      <td>0.266064</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.258708</td>\n",
       "      <td>0.278215</td>\n",
       "      <td>0.253510</td>\n",
       "      <td>0.263075</td>\n",
       "      <td>0.269543</td>\n",
       "      <td>0.239567</td>\n",
       "      <td>0.242770</td>\n",
       "      <td>0.253262</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.262150</td>\n",
       "      <td>0.274272</td>\n",
       "      <td>0.240290</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>0.263576</td>\n",
       "      <td>0.230973</td>\n",
       "      <td>0.232951</td>\n",
       "      <td>0.247039</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.268369</td>\n",
       "      <td>0.273187</td>\n",
       "      <td>0.231391</td>\n",
       "      <td>0.248651</td>\n",
       "      <td>0.260962</td>\n",
       "      <td>0.226332</td>\n",
       "      <td>0.227692</td>\n",
       "      <td>0.245479</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target  x_right_hand_0  x_right_hand_1  x_right_hand_10  \\\n",
       "0            1  bathroom        0.264414        0.291182         0.288854   \n",
       "1            1  bathroom        0.259750        0.284009         0.269205   \n",
       "2            1  bathroom        0.258708        0.278215         0.253510   \n",
       "3            1  bathroom        0.262150        0.274272         0.240290   \n",
       "4            1  bathroom        0.268369        0.273187         0.231391   \n",
       "\n",
       "   x_right_hand_11  x_right_hand_12  x_right_hand_13  x_right_hand_14  \\\n",
       "0         0.293428         0.294785         0.266834         0.274996   \n",
       "1         0.276955         0.280713         0.251700         0.257347   \n",
       "2         0.263075         0.269543         0.239567         0.242770   \n",
       "3         0.254193         0.263576         0.230973         0.232951   \n",
       "4         0.248651         0.260962         0.226332         0.227692   \n",
       "\n",
       "   x_right_hand_15  ...  y_left_hand_19  y_left_hand_2  y_left_hand_20  \\\n",
       "0         0.279632  ...             NaN            NaN             NaN   \n",
       "1         0.266064  ...             NaN            NaN             NaN   \n",
       "2         0.253262  ...             NaN            NaN             NaN   \n",
       "3         0.247039  ...             NaN            NaN             NaN   \n",
       "4         0.245479  ...             NaN            NaN             NaN   \n",
       "\n",
       "   y_left_hand_3  y_left_hand_4  y_left_hand_5  y_left_hand_6  y_left_hand_7  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   y_left_hand_8  y_left_hand_9  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2764\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_test) == len(test_data))\n",
    "print(len(df_train) == len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_train = pd.read_csv(\"train.csv\", usecols=[\"sequence_id\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrases_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the lengths of the video sequences\n",
    "video_lengths = df.groupby('sequence_id').size()\n",
    "max_seq_length = list(video_lengths.index)[-1]\n",
    "# max_seq_length = 30\n",
    "# Plot the histogram\n",
    "plt.hist(video_lengths, bins=30)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Video Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Video Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a one-hot encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_videos(df):\n",
    "    # Create a new DataFrame to store the filled rows\n",
    "    filled_df = pd.DataFrame()\n",
    "    target = []\n",
    "\n",
    "\n",
    "    # Iterate over each group and fill remaining rows with zero\n",
    "    for _, group in df.groupby('sequence_id'):\n",
    "        remaining_rows = max_seq_length - len(group)\n",
    "        if remaining_rows > 0:\n",
    "            zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "            zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "            zeros_df['target'] = group['target'].unique()[0]\n",
    "            group = pd.concat([group, zeros_df])\n",
    "        \n",
    "            filled_df = filled_df.append(group)\n",
    "            target.append(group[\"target\"].unique()[0])\n",
    "        \n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df, target\n",
    "\n",
    "def padding_labels(target):\n",
    "    # # Convert each text in the list to numerical labels\n",
    "    # numerical_labels_list = []\n",
    "    # for text in target:\n",
    "    #     numerical_labels = [char_to_pred[char] for char in text]\n",
    "    #     numerical_labels_list.append(torch.tensor(numerical_labels))\n",
    "\n",
    "    # # Pad the sequences to the maximum length\n",
    "    # padded_labels = pad_sequence(numerical_labels_list, batch_first=True)\n",
    "    # return np.array(padded_labels)\n",
    "\n",
    "    \n",
    "    integer_encoded = label_encoder.fit_transform(target)\n",
    "    integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "\n",
    "    # Encode the word \"Hello\"\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)  # sparse=False to get a numpy array as output\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8964 83\n"
     ]
    }
   ],
   "source": [
    "X_train, target = padding_videos(df_train)\n",
    "y_train = padding_labels(target)\n",
    "del X_train[\"sequence_id\"] \n",
    "del X_train[\"target\"] \n",
    "\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_right_hand_0</th>\n",
       "      <th>x_right_hand_1</th>\n",
       "      <th>x_right_hand_10</th>\n",
       "      <th>x_right_hand_11</th>\n",
       "      <th>x_right_hand_12</th>\n",
       "      <th>x_right_hand_13</th>\n",
       "      <th>x_right_hand_14</th>\n",
       "      <th>x_right_hand_15</th>\n",
       "      <th>x_right_hand_16</th>\n",
       "      <th>x_right_hand_17</th>\n",
       "      <th>...</th>\n",
       "      <th>y_left_hand_19</th>\n",
       "      <th>y_left_hand_2</th>\n",
       "      <th>y_left_hand_20</th>\n",
       "      <th>y_left_hand_3</th>\n",
       "      <th>y_left_hand_4</th>\n",
       "      <th>y_left_hand_5</th>\n",
       "      <th>y_left_hand_6</th>\n",
       "      <th>y_left_hand_7</th>\n",
       "      <th>y_left_hand_8</th>\n",
       "      <th>y_left_hand_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428059</td>\n",
       "      <td>0.455014</td>\n",
       "      <td>0.435321</td>\n",
       "      <td>0.437820</td>\n",
       "      <td>0.442903</td>\n",
       "      <td>0.419692</td>\n",
       "      <td>0.418911</td>\n",
       "      <td>0.424760</td>\n",
       "      <td>0.430611</td>\n",
       "      <td>0.401609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.427634</td>\n",
       "      <td>0.453865</td>\n",
       "      <td>0.434901</td>\n",
       "      <td>0.436315</td>\n",
       "      <td>0.440850</td>\n",
       "      <td>0.420557</td>\n",
       "      <td>0.418870</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.429443</td>\n",
       "      <td>0.401846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.426946</td>\n",
       "      <td>0.452502</td>\n",
       "      <td>0.435022</td>\n",
       "      <td>0.435967</td>\n",
       "      <td>0.440036</td>\n",
       "      <td>0.420173</td>\n",
       "      <td>0.418230</td>\n",
       "      <td>0.422908</td>\n",
       "      <td>0.428222</td>\n",
       "      <td>0.401334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427547</td>\n",
       "      <td>0.452244</td>\n",
       "      <td>0.435155</td>\n",
       "      <td>0.436643</td>\n",
       "      <td>0.440307</td>\n",
       "      <td>0.419982</td>\n",
       "      <td>0.417959</td>\n",
       "      <td>0.423094</td>\n",
       "      <td>0.428289</td>\n",
       "      <td>0.401209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.428912</td>\n",
       "      <td>0.455155</td>\n",
       "      <td>0.435010</td>\n",
       "      <td>0.437031</td>\n",
       "      <td>0.440924</td>\n",
       "      <td>0.420212</td>\n",
       "      <td>0.418424</td>\n",
       "      <td>0.423934</td>\n",
       "      <td>0.428973</td>\n",
       "      <td>0.401731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8964 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_right_hand_0  x_right_hand_1  x_right_hand_10  x_right_hand_11  \\\n",
       "0           0.428059        0.455014         0.435321         0.437820   \n",
       "1           0.427634        0.453865         0.434901         0.436315   \n",
       "2           0.426946        0.452502         0.435022         0.435967   \n",
       "3           0.427547        0.452244         0.435155         0.436643   \n",
       "4           0.428912        0.455155         0.435010         0.437031   \n",
       "...              ...             ...              ...              ...   \n",
       "8959        0.000000        0.000000         0.000000         0.000000   \n",
       "8960        0.000000        0.000000         0.000000         0.000000   \n",
       "8961        0.000000        0.000000         0.000000         0.000000   \n",
       "8962        0.000000        0.000000         0.000000         0.000000   \n",
       "8963        0.000000        0.000000         0.000000         0.000000   \n",
       "\n",
       "      x_right_hand_12  x_right_hand_13  x_right_hand_14  x_right_hand_15  \\\n",
       "0            0.442903         0.419692         0.418911         0.424760   \n",
       "1            0.440850         0.420557         0.418870         0.423867   \n",
       "2            0.440036         0.420173         0.418230         0.422908   \n",
       "3            0.440307         0.419982         0.417959         0.423094   \n",
       "4            0.440924         0.420212         0.418424         0.423934   \n",
       "...               ...              ...              ...              ...   \n",
       "8959         0.000000         0.000000         0.000000         0.000000   \n",
       "8960         0.000000         0.000000         0.000000         0.000000   \n",
       "8961         0.000000         0.000000         0.000000         0.000000   \n",
       "8962         0.000000         0.000000         0.000000         0.000000   \n",
       "8963         0.000000         0.000000         0.000000         0.000000   \n",
       "\n",
       "      x_right_hand_16  x_right_hand_17  ...  y_left_hand_19  y_left_hand_2  \\\n",
       "0            0.430611         0.401609  ...             0.0            0.0   \n",
       "1            0.429443         0.401846  ...             0.0            0.0   \n",
       "2            0.428222         0.401334  ...             0.0            0.0   \n",
       "3            0.428289         0.401209  ...             0.0            0.0   \n",
       "4            0.428973         0.401731  ...             0.0            0.0   \n",
       "...               ...              ...  ...             ...            ...   \n",
       "8959         0.000000         0.000000  ...             0.0            0.0   \n",
       "8960         0.000000         0.000000  ...             0.0            0.0   \n",
       "8961         0.000000         0.000000  ...             0.0            0.0   \n",
       "8962         0.000000         0.000000  ...             0.0            0.0   \n",
       "8963         0.000000         0.000000  ...             0.0            0.0   \n",
       "\n",
       "      y_left_hand_20  y_left_hand_3  y_left_hand_4  y_left_hand_5  \\\n",
       "0                0.0            0.0            0.0            0.0   \n",
       "1                0.0            0.0            0.0            0.0   \n",
       "2                0.0            0.0            0.0            0.0   \n",
       "3                0.0            0.0            0.0            0.0   \n",
       "4                0.0            0.0            0.0            0.0   \n",
       "...              ...            ...            ...            ...   \n",
       "8959             0.0            0.0            0.0            0.0   \n",
       "8960             0.0            0.0            0.0            0.0   \n",
       "8961             0.0            0.0            0.0            0.0   \n",
       "8962             0.0            0.0            0.0            0.0   \n",
       "8963             0.0            0.0            0.0            0.0   \n",
       "\n",
       "      y_left_hand_6  y_left_hand_7  y_left_hand_8  y_left_hand_9  \n",
       "0               0.0            0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0            0.0  \n",
       "...             ...            ...            ...            ...  \n",
       "8959            0.0            0.0            0.0            0.0  \n",
       "8960            0.0            0.0            0.0            0.0  \n",
       "8961            0.0            0.0            0.0            0.0  \n",
       "8962            0.0            0.0            0.0            0.0  \n",
       "8963            0.0            0.0            0.0            0.0  \n",
       "\n",
       "[8964 rows x 84 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 25\n"
     ]
    }
   ],
   "source": [
    "X_test, target = padding_videos(df_test)\n",
    "y_test = padding_labels(target)\n",
    "del X_test[\"sequence_id\"] \n",
    "del X_test[\"target\"] \n",
    "\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train) + len(y_test) == len(df[\"sequence_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_X(X):\n",
    "    # Define the number of rows to be flattened\n",
    "    rows_to_flatten = max_seq_length\n",
    "\n",
    "    data_array = X.to_numpy()\n",
    "\n",
    "    # Get the number of resulting rows in the output array\n",
    "    resulting_rows = data_array.shape[0] // rows_to_flatten\n",
    "\n",
    "    # Reshape the array to have (resulting_rows, rows_to_flatten, 80) shape\n",
    "    reshaped_array = data_array[:resulting_rows * rows_to_flatten].reshape(resulting_rows, rows_to_flatten, -1)\n",
    "\n",
    "    # Flatten the reshaped array along the second axis (axis=1) to get (resulting_rows, 13600) shape\n",
    "    flattened_array = reshaped_array.reshape(resulting_rows, -1)\n",
    "\n",
    "    return flattened_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_size =  num_classes * num_timesteps * num_features\n",
    "# actual_size = X.iloc[:, :num_features].values.size\n",
    "# if expected_size != actual_size:\n",
    "#     raise ValueError(\"The total number of elements in the DataFrame does not match the expected size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = int(len(X_test)/max_seq_length)\n",
    "num_features = len(get_needed_cols())\n",
    "num_classes = len(y_test[1])\n",
    "\n",
    "X_test = X_test.values.reshape(num_samples, max_seq_length, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_train = int(len(X_train)/max_seq_length)\n",
    "num_features_train = len(get_needed_cols())\n",
    "num_classes_train = len(y_train[1])\n",
    "\n",
    "X_train = X_train.values.reshape(num_samples_train, max_seq_length, num_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = flat_X(X_train)\n",
    "# X_test = flat_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (83, 108, 84) (83, 25)\n",
      "Test: (25, 108, 84) (25, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "La entrada son las coordenadas de las manos. Cada video cuenta con n cantidad de filas, 84 columnas (21 columnas por cada coordenada y por ambas manos).\n",
    "La salida es la frase. La frase se representa por un entero que da el one hot encoder.\n",
    "\n",
    "Se usa convoluciones para resaltar las caracteristicas en la entrada. Debido a que la entrada son coordenadas normalizadas de un video, se supone que funciona igual que si la entrada fuera una imagen. Estas redes extraen caracteristicas de forma automatica para clasificar objetos luego. Al buscar patrones, se espera que pueda predecir un video que ya ha sido entrenado previamente.\n",
    "\n",
    "Se reduce el tamaño de la entrada haciendo uso de max pooling y flatten.\n",
    "\n",
    "Se hace uso de Dense para conectar entradas con salidas.\n",
    "\n",
    "Se hace uso de Dropout para evitar el sobreajuste.\n",
    "\n",
    "Relu elimina negativos. \n",
    "Sigmoid nos ayuda a obtener la probabilidad de que un ejemplo pertenezca a la clase positiva.\n",
    "Softmax hace clasificacion multiclase (en nuestro caso las palabras a predecir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 3.3889 - accuracy: 0.0361\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 3.2731 - accuracy: 0.0482\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 3.1390 - accuracy: 0.0723\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 3.0113 - accuracy: 0.0964\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 3.0622 - accuracy: 0.0964\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.9739 - accuracy: 0.0843\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 2.9490 - accuracy: 0.1205\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 2.9907 - accuracy: 0.1325\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.8935 - accuracy: 0.1446\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 2.8583 - accuracy: 0.1566\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 2.7367 - accuracy: 0.1446\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 2.7833 - accuracy: 0.1205\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 2.8596 - accuracy: 0.1446\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.7293 - accuracy: 0.1325\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 2.6375 - accuracy: 0.3012\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 2.6507 - accuracy: 0.2048\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 2.6536 - accuracy: 0.2530\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 2.5461 - accuracy: 0.2651\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 2.5326 - accuracy: 0.2892\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 2.5954 - accuracy: 0.3133\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 2.4356 - accuracy: 0.3735\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 2.5581 - accuracy: 0.2651\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 2.5427 - accuracy: 0.2410\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 2.4761 - accuracy: 0.2892\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 2.4287 - accuracy: 0.3012\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.6708 - accuracy: 0.3600\n",
      "Test accuracy: 0.36000001430511475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), strides=(1, 1), input_shape=(max_seq_length, num_features_train, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(25, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes_train, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Find the most likely prediction for each sample\n",
    "most_likely_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 13, 18,  3,  4,  5, 14,  7,  8, 20, 14, 21, 15, 13, 18, 13, 21,\n",
       "       21, 18, 13, 18, 21, 22, 14,  3], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = label_encoder.inverse_transform(most_likely_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels = train_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctamente predecido en:  eat food\n",
      "Correctamente predecido en:  father\n",
      "Correctamente predecido en:  fine\n",
      "Correctamente predecido en:  go to\n",
      "Correctamente predecido en:  hello\n",
      "Correctamente predecido en:  milk\n",
      "Correctamente predecido en:  repeat\n",
      "Correctamente predecido en:  thank you\n",
      "Correctamente predecido en:  want\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted_labels)):\n",
    "    if (predicted_labels[i] == expected_labels[i]):\n",
    "        print(\"Correctamente predecido en: \", predicted_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length,num_features)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = max_seq_length * 80\n",
    "# num_timesteps = max_seq_length * num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = torch.from_numpy(X_train).float()\n",
    "# X_test = torch.from_numpy(X_test).float()\n",
    "# y_train = torch.from_numpy(y_train).float()\n",
    "# y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ASLModel(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(ASLModel, self).__init__()\n",
    "#         # RuntimeError: mat1 and mat2 shapes cannot be multiplied (6912x84 and 108x2048)\n",
    "#         # (6912x84 and 83x2048)\n",
    "\n",
    "#         self.linear1 = nn.Linear(input_size, 2048)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(2048, 1024)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.linear3 = nn.Linear(1024, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x = self.linear1(x)\n",
    "#         # x = self.relu1(x)\n",
    "#         # x = self.linear2(x)\n",
    "#         # x = self.relu2(x)\n",
    "#         # x = self.linear3(x)\n",
    "#         # print(x.shape)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Initialization\n",
    "# model = ASLModel(input_size=X_train.shape[1], output_size=y_train.shape[1]).to(device)\n",
    "# # Optimization Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preparation\n",
    "# train_data = TensorDataset(X_train, y_train)\n",
    "# test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# # DataLoader\n",
    "# BATCH_SIZE = 16\n",
    "# train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reverse the JSON dictionary\n",
    "# pred_to_char = {value: key for key, value in char_to_pred.items()}\n",
    "# def reverse_to_char(data):\n",
    "#     phrase = \"\"\n",
    "#     for i in data:\n",
    "#         phrase += str(pred_to_char.get(int(i.item())) if int(i.item()) in pred_to_char else \"_\")\n",
    "    \n",
    "#     return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RuntimeError: The size of tensor a (108) must match the size of tensor b (64) at non-singleton dimension \n",
    "# for inputs, targets in train_loader:\n",
    "#     print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 5\n",
    "# loss_fn = nn.SmoothL1Loss() \n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     train_correct = 0\n",
    "\n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # labels = labels.long()\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Calculate the loss\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "#         # Accumulate the loss\n",
    "#         train_loss += loss.item() * inputs.size(0)\n",
    "#         # Accumulate the total number of samples\n",
    "#         train_correct += inputs.size(0)\n",
    "\n",
    "#     train_loss = train_loss / train_correct\n",
    "#     train_accuracy = train_correct / len(train_data)\n",
    "\n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     test_correct = 0\n",
    "#     levenshtein_distance = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             # labels = labels.long()\n",
    "\n",
    "#             print(\"input\")\n",
    "#             print(inputs)\n",
    "#             outputs = model(inputs)     \n",
    "#             print(outputs)\n",
    "#             # Get the predicted labels\n",
    "#             _, predicted = torch.max(outputs.data, dim=1)\n",
    "#             # Calculate the loss\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             # Accumulate the loss\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             # Accumulate the total number of samples\n",
    "#             test_correct += inputs.size(0)\n",
    "\n",
    "#             print(predicted.size())\n",
    "#             outputs_array = outputs.detach().cpu().numpy()\n",
    "#             targets_array = labels.detach().cpu().numpy()\n",
    "#             # Convert predictions and targets to letter sequences\n",
    "#             pred_labels = [[pred_to_char[int(label)] for label in output if int(label) in pred_to_char ] if len(output) > 0 else [] for output in outputs_array.round()]\n",
    "#             target_labels = [[pred_to_char[label] for label in target if int(label) in pred_to_char  ] if len(target) > 0 else [] for target in targets_array.round()]\n",
    "\n",
    "#             print(\"Predicted: \", pred_labels)\n",
    "#             print(\"Expected: \", target_labels)\n",
    "#             break\n",
    "\n",
    "#             # # Calculate Levenshtein distance\n",
    "#             # levenshtein_distance += calculate_levenshtein_distance(pred_labels, target_labels)\n",
    "            \n",
    "#     # test_loss = test_loss / test_correct\n",
    "#     # test_accuracy = test_correct / len(test_data)\n",
    "#     # average_levenshtein_distance = levenshtein_distance / len(test_data)\n",
    "\n",
    "#     # Print epoch results\n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "#     # print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n",
    "#     # print(f\"Average Levenshtein Distance: {average_levenshtein_distance:.4f}\")\n",
    "#     print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
