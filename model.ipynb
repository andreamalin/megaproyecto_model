{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"validation.csv\")\n",
    "char_to_pred = json.load(open(\"data/character_to_prediction_index.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target\n",
       "0            1  bathroom\n",
       "1            1  bathroom\n",
       "2            1  bathroom\n",
       "3            1  bathroom\n",
       "4            1  bathroom"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train data--------------------\n",
      "Cantidad de filas : 3531\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Train data--------------------\")\n",
    "print(f\"Cantidad de filas : {train_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {train_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation data--------------------\n",
      "Cantidad de filas : 1197\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Validation data--------------------\")\n",
    "print(f\"Cantidad de filas : {test_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {test_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3531.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.212971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.784160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_id\n",
       "count  3531.000000\n",
       "mean     54.212971\n",
       "std      31.784160\n",
       "min       1.000000\n",
       "25%      26.000000\n",
       "50%      55.000000\n",
       "75%      82.000000\n",
       "max     107.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein Distance\n",
    "* Ref: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/#:~:text=The%20Levenshtein%20distance%20is%20a,transform%20one%20word%20into%20another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDistances(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levenshteinDistanceDP(\"kelm\", \"hello\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo se obtienen 20 indices de las coordenadas x y y, ya que son las unicas que han sido altamente entrenadas del modelo mediapipe de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_cols():\n",
    "    cols = []\n",
    "\n",
    "    for i in range(21):\n",
    "        cols.append(f'x_right_hand_{i}')\n",
    "        cols.append(f'y_right_hand_{i}')\n",
    "        cols.append(f'x_left_hand_{i}')\n",
    "        cols.append(f'y_left_hand_{i}')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df_test = df[df['sequence_id'].isin(test_data['sequence_id'])]\n",
    "df_train = df[df['sequence_id'].isin(train_data['sequence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "      <th>x_right_hand_0</th>\n",
       "      <th>x_right_hand_1</th>\n",
       "      <th>x_right_hand_10</th>\n",
       "      <th>x_right_hand_11</th>\n",
       "      <th>x_right_hand_12</th>\n",
       "      <th>x_right_hand_13</th>\n",
       "      <th>x_right_hand_14</th>\n",
       "      <th>x_right_hand_15</th>\n",
       "      <th>...</th>\n",
       "      <th>y_left_hand_19</th>\n",
       "      <th>y_left_hand_2</th>\n",
       "      <th>y_left_hand_20</th>\n",
       "      <th>y_left_hand_3</th>\n",
       "      <th>y_left_hand_4</th>\n",
       "      <th>y_left_hand_5</th>\n",
       "      <th>y_left_hand_6</th>\n",
       "      <th>y_left_hand_7</th>\n",
       "      <th>y_left_hand_8</th>\n",
       "      <th>y_left_hand_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.265968</td>\n",
       "      <td>0.292575</td>\n",
       "      <td>0.288380</td>\n",
       "      <td>0.292631</td>\n",
       "      <td>0.294420</td>\n",
       "      <td>0.267287</td>\n",
       "      <td>0.274185</td>\n",
       "      <td>0.278704</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.261926</td>\n",
       "      <td>0.285769</td>\n",
       "      <td>0.270102</td>\n",
       "      <td>0.277428</td>\n",
       "      <td>0.281503</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.257510</td>\n",
       "      <td>0.266150</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.261108</td>\n",
       "      <td>0.279633</td>\n",
       "      <td>0.253392</td>\n",
       "      <td>0.264042</td>\n",
       "      <td>0.271299</td>\n",
       "      <td>0.240579</td>\n",
       "      <td>0.244216</td>\n",
       "      <td>0.256161</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.264250</td>\n",
       "      <td>0.275873</td>\n",
       "      <td>0.238741</td>\n",
       "      <td>0.254208</td>\n",
       "      <td>0.264493</td>\n",
       "      <td>0.231736</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.247959</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.270280</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.249087</td>\n",
       "      <td>0.260723</td>\n",
       "      <td>0.226887</td>\n",
       "      <td>0.228234</td>\n",
       "      <td>0.246714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target  x_right_hand_0  x_right_hand_1  x_right_hand_10  \\\n",
       "0            1  bathroom        0.265968        0.292575         0.288380   \n",
       "1            1  bathroom        0.261926        0.285769         0.270102   \n",
       "2            1  bathroom        0.261108        0.279633         0.253392   \n",
       "3            1  bathroom        0.264250        0.275873         0.238741   \n",
       "4            1  bathroom        0.270280        0.274816         0.231373   \n",
       "\n",
       "   x_right_hand_11  x_right_hand_12  x_right_hand_13  x_right_hand_14  \\\n",
       "0         0.292631         0.294420         0.267287         0.274185   \n",
       "1         0.277428         0.281503         0.252827         0.257510   \n",
       "2         0.264042         0.271299         0.240579         0.244216   \n",
       "3         0.254208         0.264493         0.231736         0.232600   \n",
       "4         0.249087         0.260723         0.226887         0.228234   \n",
       "\n",
       "   x_right_hand_15  ...  y_left_hand_19  y_left_hand_2  y_left_hand_20  \\\n",
       "0         0.278704  ...             NaN            NaN             NaN   \n",
       "1         0.266150  ...             NaN            NaN             NaN   \n",
       "2         0.256161  ...             NaN            NaN             NaN   \n",
       "3         0.247959  ...             NaN            NaN             NaN   \n",
       "4         0.246714  ...             NaN            NaN             NaN   \n",
       "\n",
       "   y_left_hand_3  y_left_hand_4  y_left_hand_5  y_left_hand_6  y_left_hand_7  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   y_left_hand_8  y_left_hand_9  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4728\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_test) == len(test_data))\n",
    "print(len(df_train) == len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_train = pd.read_csv(\"train.csv\", usecols=[\"sequence_id\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3531"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrases_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the lengths of the video sequences\n",
    "video_lengths = df.groupby('sequence_id').size()\n",
    "max_seq_length = list(video_lengths.index)[-1]\n",
    "# max_seq_length = 30\n",
    "# Plot the histogram\n",
    "plt.hist(video_lengths, bins=30)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Video Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Video Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a one-hot encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_videos(df):\n",
    "    # Create a new DataFrame to store the filled rows\n",
    "    filled_df = pd.DataFrame()\n",
    "    target = []\n",
    "\n",
    "\n",
    "    # Iterate over each group and fill remaining rows with zero\n",
    "    for _, group in df.groupby('sequence_id'):\n",
    "        remaining_rows = max_seq_length - len(group)\n",
    "        if remaining_rows > 0:\n",
    "            zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "            zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "            zeros_df['target'] = group['target'].unique()[0]\n",
    "            group = pd.concat([group, zeros_df])\n",
    "        \n",
    "            filled_df = filled_df.append(group)\n",
    "            target.append(group[\"target\"].unique()[0])\n",
    "        \n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df, target\n",
    "\n",
    "def padding_labels(target):\n",
    "    # # Convert each text in the list to numerical labels\n",
    "    # numerical_labels_list = []\n",
    "    # for text in target:\n",
    "    #     numerical_labels = [char_to_pred[char] for char in text]\n",
    "    #     numerical_labels_list.append(torch.tensor(numerical_labels))\n",
    "\n",
    "    # # Pad the sequences to the maximum length\n",
    "    # padded_labels = pad_sequence(numerical_labels_list, batch_first=True)\n",
    "    # return np.array(padded_labels)\n",
    "\n",
    "    \n",
    "    integer_encoded = label_encoder.fit_transform(target)\n",
    "    integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "\n",
    "    # Encode the word \"Hello\"\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)  # sparse=False to get a numpy array as output\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8964 83\n"
     ]
    }
   ],
   "source": [
    "X_train, target = padding_videos(df_train)\n",
    "y_train = padding_labels(target)\n",
    "del X_train[\"sequence_id\"] \n",
    "del X_train[\"target\"] \n",
    "\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_right_hand_0</th>\n",
       "      <th>x_right_hand_1</th>\n",
       "      <th>x_right_hand_10</th>\n",
       "      <th>x_right_hand_11</th>\n",
       "      <th>x_right_hand_12</th>\n",
       "      <th>x_right_hand_13</th>\n",
       "      <th>x_right_hand_14</th>\n",
       "      <th>x_right_hand_15</th>\n",
       "      <th>x_right_hand_16</th>\n",
       "      <th>x_right_hand_17</th>\n",
       "      <th>...</th>\n",
       "      <th>y_left_hand_19</th>\n",
       "      <th>y_left_hand_2</th>\n",
       "      <th>y_left_hand_20</th>\n",
       "      <th>y_left_hand_3</th>\n",
       "      <th>y_left_hand_4</th>\n",
       "      <th>y_left_hand_5</th>\n",
       "      <th>y_left_hand_6</th>\n",
       "      <th>y_left_hand_7</th>\n",
       "      <th>y_left_hand_8</th>\n",
       "      <th>y_left_hand_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.265968</td>\n",
       "      <td>0.292575</td>\n",
       "      <td>0.288380</td>\n",
       "      <td>0.292631</td>\n",
       "      <td>0.294420</td>\n",
       "      <td>0.267287</td>\n",
       "      <td>0.274185</td>\n",
       "      <td>0.278704</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.250112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261926</td>\n",
       "      <td>0.285769</td>\n",
       "      <td>0.270102</td>\n",
       "      <td>0.277428</td>\n",
       "      <td>0.281503</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.257510</td>\n",
       "      <td>0.266150</td>\n",
       "      <td>0.270304</td>\n",
       "      <td>0.237020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261108</td>\n",
       "      <td>0.279633</td>\n",
       "      <td>0.253392</td>\n",
       "      <td>0.264042</td>\n",
       "      <td>0.271299</td>\n",
       "      <td>0.240579</td>\n",
       "      <td>0.244216</td>\n",
       "      <td>0.256161</td>\n",
       "      <td>0.262884</td>\n",
       "      <td>0.226568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.264250</td>\n",
       "      <td>0.275873</td>\n",
       "      <td>0.238741</td>\n",
       "      <td>0.254208</td>\n",
       "      <td>0.264493</td>\n",
       "      <td>0.231736</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.247959</td>\n",
       "      <td>0.256916</td>\n",
       "      <td>0.221145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270280</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.249087</td>\n",
       "      <td>0.260723</td>\n",
       "      <td>0.226887</td>\n",
       "      <td>0.228234</td>\n",
       "      <td>0.246714</td>\n",
       "      <td>0.258701</td>\n",
       "      <td>0.219249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8964 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_right_hand_0  x_right_hand_1  x_right_hand_10  x_right_hand_11  \\\n",
       "0           0.265968        0.292575         0.288380         0.292631   \n",
       "1           0.261926        0.285769         0.270102         0.277428   \n",
       "2           0.261108        0.279633         0.253392         0.264042   \n",
       "3           0.264250        0.275873         0.238741         0.254208   \n",
       "4           0.270280        0.274816         0.231373         0.249087   \n",
       "...              ...             ...              ...              ...   \n",
       "8959        0.000000        0.000000         0.000000         0.000000   \n",
       "8960        0.000000        0.000000         0.000000         0.000000   \n",
       "8961        0.000000        0.000000         0.000000         0.000000   \n",
       "8962        0.000000        0.000000         0.000000         0.000000   \n",
       "8963        0.000000        0.000000         0.000000         0.000000   \n",
       "\n",
       "      x_right_hand_12  x_right_hand_13  x_right_hand_14  x_right_hand_15  \\\n",
       "0            0.294420         0.267287         0.274185         0.278704   \n",
       "1            0.281503         0.252827         0.257510         0.266150   \n",
       "2            0.271299         0.240579         0.244216         0.256161   \n",
       "3            0.264493         0.231736         0.232600         0.247959   \n",
       "4            0.260723         0.226887         0.228234         0.246714   \n",
       "...               ...              ...              ...              ...   \n",
       "8959         0.000000         0.000000         0.000000         0.000000   \n",
       "8960         0.000000         0.000000         0.000000         0.000000   \n",
       "8961         0.000000         0.000000         0.000000         0.000000   \n",
       "8962         0.000000         0.000000         0.000000         0.000000   \n",
       "8963         0.000000         0.000000         0.000000         0.000000   \n",
       "\n",
       "      x_right_hand_16  x_right_hand_17  ...  y_left_hand_19  y_left_hand_2  \\\n",
       "0            0.280200         0.250112  ...             0.0            0.0   \n",
       "1            0.270304         0.237020  ...             0.0            0.0   \n",
       "2            0.262884         0.226568  ...             0.0            0.0   \n",
       "3            0.256916         0.221145  ...             0.0            0.0   \n",
       "4            0.258701         0.219249  ...             0.0            0.0   \n",
       "...               ...              ...  ...             ...            ...   \n",
       "8959         0.000000         0.000000  ...             0.0            0.0   \n",
       "8960         0.000000         0.000000  ...             0.0            0.0   \n",
       "8961         0.000000         0.000000  ...             0.0            0.0   \n",
       "8962         0.000000         0.000000  ...             0.0            0.0   \n",
       "8963         0.000000         0.000000  ...             0.0            0.0   \n",
       "\n",
       "      y_left_hand_20  y_left_hand_3  y_left_hand_4  y_left_hand_5  \\\n",
       "0                0.0            0.0            0.0            0.0   \n",
       "1                0.0            0.0            0.0            0.0   \n",
       "2                0.0            0.0            0.0            0.0   \n",
       "3                0.0            0.0            0.0            0.0   \n",
       "4                0.0            0.0            0.0            0.0   \n",
       "...              ...            ...            ...            ...   \n",
       "8959             0.0            0.0            0.0            0.0   \n",
       "8960             0.0            0.0            0.0            0.0   \n",
       "8961             0.0            0.0            0.0            0.0   \n",
       "8962             0.0            0.0            0.0            0.0   \n",
       "8963             0.0            0.0            0.0            0.0   \n",
       "\n",
       "      y_left_hand_6  y_left_hand_7  y_left_hand_8  y_left_hand_9  \n",
       "0               0.0            0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0            0.0  \n",
       "...             ...            ...            ...            ...  \n",
       "8959            0.0            0.0            0.0            0.0  \n",
       "8960            0.0            0.0            0.0            0.0  \n",
       "8961            0.0            0.0            0.0            0.0  \n",
       "8962            0.0            0.0            0.0            0.0  \n",
       "8963            0.0            0.0            0.0            0.0  \n",
       "\n",
       "[8964 rows x 84 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 25\n"
     ]
    }
   ],
   "source": [
    "X_test, target = padding_videos(df_test)\n",
    "y_test = padding_labels(target)\n",
    "del X_test[\"sequence_id\"] \n",
    "del X_test[\"target\"] \n",
    "\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train) + len(y_test) == len(df[\"sequence_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_X(X):\n",
    "    # Define the number of rows to be flattened\n",
    "    rows_to_flatten = max_seq_length\n",
    "\n",
    "    data_array = X.to_numpy()\n",
    "\n",
    "    # Get the number of resulting rows in the output array\n",
    "    resulting_rows = data_array.shape[0] // rows_to_flatten\n",
    "\n",
    "    # Reshape the array to have (resulting_rows, rows_to_flatten, 80) shape\n",
    "    reshaped_array = data_array[:resulting_rows * rows_to_flatten].reshape(resulting_rows, rows_to_flatten, -1)\n",
    "\n",
    "    # Flatten the reshaped array along the second axis (axis=1) to get (resulting_rows, 13600) shape\n",
    "    flattened_array = reshaped_array.reshape(resulting_rows, -1)\n",
    "\n",
    "    return flattened_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_size =  num_classes * num_timesteps * num_features\n",
    "# actual_size = X.iloc[:, :num_features].values.size\n",
    "# if expected_size != actual_size:\n",
    "#     raise ValueError(\"The total number of elements in the DataFrame does not match the expected size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = int(len(X_test)/max_seq_length)\n",
    "num_features = len(get_needed_cols())\n",
    "num_classes = len(y_test[1])\n",
    "\n",
    "X_test = X_test.values.reshape(num_samples, max_seq_length, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_train = int(len(X_train)/max_seq_length)\n",
    "num_features_train = len(get_needed_cols())\n",
    "num_classes_train = len(y_train[1])\n",
    "\n",
    "X_train = X_train.values.reshape(num_samples_train, max_seq_length, num_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = flat_X(X_train)\n",
    "# X_test = flat_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (83, 108, 84) (83, 25)\n",
      "Test: (25, 108, 84) (25, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "La entrada son las coordenadas de las manos. Cada video cuenta con n cantidad de filas, 84 columnas (21 columnas por cada coordenada y por ambas manos).\n",
    "La salida es la frase. La frase se representa por un entero que da el one hot encoder.\n",
    "\n",
    "Se usa convoluciones para resaltar las caracteristicas en la entrada. Debido a que la entrada son coordenadas normalizadas de un video, se supone que funciona igual que si la entrada fuera una imagen. Estas redes extraen caracteristicas de forma automatica para clasificar objetos luego. Al buscar patrones, se espera que pueda predecir un video que ya ha sido entrenado previamente.\n",
    "\n",
    "Se reduce el tamaño de la entrada haciendo uso de max pooling y flatten.\n",
    "\n",
    "Se hace uso de Dense para conectar entradas con salidas.\n",
    "\n",
    "Se hace uso de Dropout para evitar el sobreajuste.\n",
    "\n",
    "Relu elimina negativos. \n",
    "Sigmoid nos ayuda a obtener la probabilidad de que un ejemplo pertenezca a la clase positiva.\n",
    "Softmax hace clasificacion multiclase (en nuestro caso las palabras a predecir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 3.3483 - accuracy: 0.0361\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 3.1960 - accuracy: 0.0361\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 3.1040 - accuracy: 0.0964\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 3.0100 - accuracy: 0.1325\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 2.9429 - accuracy: 0.0964\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 2.8689 - accuracy: 0.1807\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 2.9295 - accuracy: 0.1205\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 2.7563 - accuracy: 0.2651\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 2.8077 - accuracy: 0.1807\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 2.7193 - accuracy: 0.2530\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 2.6635 - accuracy: 0.2289\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 2.5676 - accuracy: 0.2530\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 2.5068 - accuracy: 0.2530\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 2.5310 - accuracy: 0.2771\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 2.3933 - accuracy: 0.3855\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 2.3489 - accuracy: 0.3494\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 2.3310 - accuracy: 0.3614\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 2.3218 - accuracy: 0.3855\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 2.2409 - accuracy: 0.4337\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 2.2095 - accuracy: 0.4337\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 2.0986 - accuracy: 0.4337\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 2.0300 - accuracy: 0.5060\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 2.1931 - accuracy: 0.4096\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 2.0982 - accuracy: 0.5422\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 1.9625 - accuracy: 0.5783\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 3.0827 - accuracy: 0.1200\n",
      "Test accuracy: 0.11999999731779099\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), strides=(1, 1), input_shape=(max_seq_length, num_features_train, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(25, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes_train, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Find the most likely prediction for each sample\n",
    "most_likely_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  0, 19,  0,  8,  0,  7,  8,  8,  7, 10,  0, 16,  0,  7,  0, 13,\n",
       "        0,  9, 24, 22, 16, 22,  7,  5], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = label_encoder.inverse_transform(most_likely_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels = train_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctamente predecido en:  hello\n",
      "Correctamente predecido en:  learn\n",
      "Correctamente predecido en:  want\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted_labels)):\n",
    "    if (predicted_labels[i] == expected_labels[i]):\n",
    "        print(\"Correctamente predecido en: \", predicted_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length,num_features)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = max_seq_length * 80\n",
    "# num_timesteps = max_seq_length * num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = torch.from_numpy(X_train).float()\n",
    "# X_test = torch.from_numpy(X_test).float()\n",
    "# y_train = torch.from_numpy(y_train).float()\n",
    "# y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ASLModel(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(ASLModel, self).__init__()\n",
    "#         # RuntimeError: mat1 and mat2 shapes cannot be multiplied (6912x84 and 108x2048)\n",
    "#         # (6912x84 and 83x2048)\n",
    "\n",
    "#         self.linear1 = nn.Linear(input_size, 2048)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(2048, 1024)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.linear3 = nn.Linear(1024, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x = self.linear1(x)\n",
    "#         # x = self.relu1(x)\n",
    "#         # x = self.linear2(x)\n",
    "#         # x = self.relu2(x)\n",
    "#         # x = self.linear3(x)\n",
    "#         # print(x.shape)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Initialization\n",
    "# model = ASLModel(input_size=X_train.shape[1], output_size=y_train.shape[1]).to(device)\n",
    "# # Optimization Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preparation\n",
    "# train_data = TensorDataset(X_train, y_train)\n",
    "# test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# # DataLoader\n",
    "# BATCH_SIZE = 16\n",
    "# train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reverse the JSON dictionary\n",
    "# pred_to_char = {value: key for key, value in char_to_pred.items()}\n",
    "# def reverse_to_char(data):\n",
    "#     phrase = \"\"\n",
    "#     for i in data:\n",
    "#         phrase += str(pred_to_char.get(int(i.item())) if int(i.item()) in pred_to_char else \"_\")\n",
    "    \n",
    "#     return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RuntimeError: The size of tensor a (108) must match the size of tensor b (64) at non-singleton dimension \n",
    "# for inputs, targets in train_loader:\n",
    "#     print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 5\n",
    "# loss_fn = nn.SmoothL1Loss() \n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     train_correct = 0\n",
    "\n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # labels = labels.long()\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Calculate the loss\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "#         # Accumulate the loss\n",
    "#         train_loss += loss.item() * inputs.size(0)\n",
    "#         # Accumulate the total number of samples\n",
    "#         train_correct += inputs.size(0)\n",
    "\n",
    "#     train_loss = train_loss / train_correct\n",
    "#     train_accuracy = train_correct / len(train_data)\n",
    "\n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     test_correct = 0\n",
    "#     levenshtein_distance = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             # labels = labels.long()\n",
    "\n",
    "#             print(\"input\")\n",
    "#             print(inputs)\n",
    "#             outputs = model(inputs)     \n",
    "#             print(outputs)\n",
    "#             # Get the predicted labels\n",
    "#             _, predicted = torch.max(outputs.data, dim=1)\n",
    "#             # Calculate the loss\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             # Accumulate the loss\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             # Accumulate the total number of samples\n",
    "#             test_correct += inputs.size(0)\n",
    "\n",
    "#             print(predicted.size())\n",
    "#             outputs_array = outputs.detach().cpu().numpy()\n",
    "#             targets_array = labels.detach().cpu().numpy()\n",
    "#             # Convert predictions and targets to letter sequences\n",
    "#             pred_labels = [[pred_to_char[int(label)] for label in output if int(label) in pred_to_char ] if len(output) > 0 else [] for output in outputs_array.round()]\n",
    "#             target_labels = [[pred_to_char[label] for label in target if int(label) in pred_to_char  ] if len(target) > 0 else [] for target in targets_array.round()]\n",
    "\n",
    "#             print(\"Predicted: \", pred_labels)\n",
    "#             print(\"Expected: \", target_labels)\n",
    "#             break\n",
    "\n",
    "#             # # Calculate Levenshtein distance\n",
    "#             # levenshtein_distance += calculate_levenshtein_distance(pred_labels, target_labels)\n",
    "            \n",
    "#     # test_loss = test_loss / test_correct\n",
    "#     # test_accuracy = test_correct / len(test_data)\n",
    "#     # average_levenshtein_distance = levenshtein_distance / len(test_data)\n",
    "\n",
    "#     # Print epoch results\n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "#     # print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n",
    "#     # print(f\"Average Levenshtein Distance: {average_levenshtein_distance:.4f}\")\n",
    "#     print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
