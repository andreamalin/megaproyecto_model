{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"validation.csv\")\n",
    "char_to_pred = json.load(open(\"data/character_to_prediction_index.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target\n",
       "0            1  bathroom\n",
       "1            1  bathroom\n",
       "2            1  bathroom\n",
       "3            1  bathroom\n",
       "4            1  bathroom"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Train data--------------------\n",
      "Cantidad de filas : 4925\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Train data--------------------\")\n",
    "print(f\"Cantidad de filas : {train_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {train_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Validation data--------------------\n",
      "Cantidad de filas : 356\n",
      "Frases unicas : ['bathroom' 'cat' 'dog' 'eat food' 'father' 'fine' 'finish' 'go to'\n",
      " 'hello' 'help' 'learn' 'like' 'me' 'milk' 'more' 'mother' 'no' 'please'\n",
      " 'repeat' 'see you later' 'sign' 'thank you' 'want' 'what' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Validation data--------------------\")\n",
    "print(f\"Cantidad de filas : {test_data.shape[0]}\")\n",
    "print(f\"Frases unicas : {test_data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (list(train_data.target.unique()) != list(test_data.target.unique())):\n",
    "    raise ValueError(\"Error between target and train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4925.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>178.241827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>105.238701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_id\n",
       "count  4925.000000\n",
       "mean    178.241827\n",
       "std     105.238701\n",
       "min       1.000000\n",
       "25%      84.000000\n",
       "50%     185.000000\n",
       "75%     267.000000\n",
       "max     359.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein Distance\n",
    "* Ref: https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/#:~:text=The%20Levenshtein%20distance%20is%20a,transform%20one%20word%20into%20another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDistances(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levenshteinDistanceDP(\"kelm\", \"hello\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo se obtienen 20 indices de las coordenadas x y y, ya que son las unicas que han sido altamente entrenadas del modelo mediapipe de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_cols():\n",
    "    cols = []\n",
    "\n",
    "    for i in range(21):\n",
    "        cols.append(f'x_right_hand_{i}')\n",
    "        cols.append(f'y_right_hand_{i}')\n",
    "        cols.append(f'x_left_hand_{i}')\n",
    "        cols.append(f'y_left_hand_{i}')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df_test = df[df['sequence_id'].isin(test_data['sequence_id'])]\n",
    "df_train = df[df['sequence_id'].isin(train_data['sequence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>target</th>\n",
       "      <th>x_right_hand_0</th>\n",
       "      <th>x_right_hand_1</th>\n",
       "      <th>x_right_hand_10</th>\n",
       "      <th>x_right_hand_11</th>\n",
       "      <th>x_right_hand_12</th>\n",
       "      <th>x_right_hand_13</th>\n",
       "      <th>x_right_hand_14</th>\n",
       "      <th>x_right_hand_15</th>\n",
       "      <th>...</th>\n",
       "      <th>y_left_hand_19</th>\n",
       "      <th>y_left_hand_2</th>\n",
       "      <th>y_left_hand_20</th>\n",
       "      <th>y_left_hand_3</th>\n",
       "      <th>y_left_hand_4</th>\n",
       "      <th>y_left_hand_5</th>\n",
       "      <th>y_left_hand_6</th>\n",
       "      <th>y_left_hand_7</th>\n",
       "      <th>y_left_hand_8</th>\n",
       "      <th>y_left_hand_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.292266</td>\n",
       "      <td>0.289448</td>\n",
       "      <td>0.293812</td>\n",
       "      <td>0.295057</td>\n",
       "      <td>0.267202</td>\n",
       "      <td>0.275095</td>\n",
       "      <td>0.279875</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.259819</td>\n",
       "      <td>0.283851</td>\n",
       "      <td>0.270306</td>\n",
       "      <td>0.277417</td>\n",
       "      <td>0.281006</td>\n",
       "      <td>0.252090</td>\n",
       "      <td>0.258523</td>\n",
       "      <td>0.266719</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.259433</td>\n",
       "      <td>0.278479</td>\n",
       "      <td>0.252867</td>\n",
       "      <td>0.263265</td>\n",
       "      <td>0.270317</td>\n",
       "      <td>0.239482</td>\n",
       "      <td>0.243582</td>\n",
       "      <td>0.254479</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.262010</td>\n",
       "      <td>0.274468</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>0.253949</td>\n",
       "      <td>0.263418</td>\n",
       "      <td>0.230673</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>0.246966</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.268236</td>\n",
       "      <td>0.273854</td>\n",
       "      <td>0.231170</td>\n",
       "      <td>0.247891</td>\n",
       "      <td>0.259833</td>\n",
       "      <td>0.226620</td>\n",
       "      <td>0.228386</td>\n",
       "      <td>0.245820</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id    target  x_right_hand_0  x_right_hand_1  x_right_hand_10  \\\n",
       "0            1  bathroom        0.265100        0.292266         0.289448   \n",
       "1            1  bathroom        0.259819        0.283851         0.270306   \n",
       "2            1  bathroom        0.259433        0.278479         0.252867   \n",
       "3            1  bathroom        0.262010        0.274468         0.239758   \n",
       "4            1  bathroom        0.268236        0.273854         0.231170   \n",
       "\n",
       "   x_right_hand_11  x_right_hand_12  x_right_hand_13  x_right_hand_14  \\\n",
       "0         0.293812         0.295057         0.267202         0.275095   \n",
       "1         0.277417         0.281006         0.252090         0.258523   \n",
       "2         0.263265         0.270317         0.239482         0.243582   \n",
       "3         0.253949         0.263418         0.230673         0.232797   \n",
       "4         0.247891         0.259833         0.226620         0.228386   \n",
       "\n",
       "   x_right_hand_15  ...  y_left_hand_19  y_left_hand_2  y_left_hand_20  \\\n",
       "0         0.279875  ...             NaN            NaN             NaN   \n",
       "1         0.266719  ...             NaN            NaN             NaN   \n",
       "2         0.254479  ...             NaN            NaN             NaN   \n",
       "3         0.246966  ...             NaN            NaN             NaN   \n",
       "4         0.245820  ...             NaN            NaN             NaN   \n",
       "\n",
       "   y_left_hand_3  y_left_hand_4  y_left_hand_5  y_left_hand_6  y_left_hand_7  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   y_left_hand_8  y_left_hand_9  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5281\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_test) == len(test_data))\n",
    "print(len(df_train) == len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the lengths of the video sequences\n",
    "video_lengths = df.groupby('sequence_id').size()\n",
    "max_seq_length = video_lengths.max()\n",
    "# max_seq_length = 30\n",
    "# Plot the histogram\n",
    "plt.hist(video_lengths, bins=30)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Video Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Video Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a one-hot encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_videos(df):\n",
    "    # Create a new DataFrame to store the filled rows\n",
    "    filled_df = pd.DataFrame()\n",
    "    target = []\n",
    "\n",
    "\n",
    "    # Iterate over each group and fill remaining rows with zero\n",
    "    for _, group in df.groupby('sequence_id'):\n",
    "        remaining_rows = max_seq_length - len(group)\n",
    "        if remaining_rows > 0:\n",
    "            zeros_df = pd.DataFrame([[0] * len(group.columns)] * remaining_rows, columns=group.columns)\n",
    "            zeros_df['sequence_id'] = group['sequence_id'].unique()[0]\n",
    "            zeros_df['target'] = group['target'].unique()[0]\n",
    "            group = pd.concat([group, zeros_df])\n",
    "        \n",
    "            filled_df = filled_df.append(group)\n",
    "            target.append(group[\"target\"].unique()[0])\n",
    "        \n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df, target\n",
    "\n",
    "def padding_labels(target):\n",
    "    integer_encoded = label_encoder.fit_transform(target)\n",
    "    integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "\n",
    "    # Encode the word \"Hello\"\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)  # sparse=False to get a numpy array as output\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13068 297\n"
     ]
    }
   ],
   "source": [
    "X_train, target = padding_videos(df_train)\n",
    "y_train = padding_labels(target)\n",
    "del X_train[\"sequence_id\"] \n",
    "del X_train[\"target\"] \n",
    "\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_right_hand_0</th>\n",
       "      <th>x_right_hand_1</th>\n",
       "      <th>x_right_hand_10</th>\n",
       "      <th>x_right_hand_11</th>\n",
       "      <th>x_right_hand_12</th>\n",
       "      <th>x_right_hand_13</th>\n",
       "      <th>x_right_hand_14</th>\n",
       "      <th>x_right_hand_15</th>\n",
       "      <th>x_right_hand_16</th>\n",
       "      <th>x_right_hand_17</th>\n",
       "      <th>...</th>\n",
       "      <th>y_left_hand_19</th>\n",
       "      <th>y_left_hand_2</th>\n",
       "      <th>y_left_hand_20</th>\n",
       "      <th>y_left_hand_3</th>\n",
       "      <th>y_left_hand_4</th>\n",
       "      <th>y_left_hand_5</th>\n",
       "      <th>y_left_hand_6</th>\n",
       "      <th>y_left_hand_7</th>\n",
       "      <th>y_left_hand_8</th>\n",
       "      <th>y_left_hand_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.292266</td>\n",
       "      <td>0.289448</td>\n",
       "      <td>0.293812</td>\n",
       "      <td>0.295057</td>\n",
       "      <td>0.267202</td>\n",
       "      <td>0.275095</td>\n",
       "      <td>0.279875</td>\n",
       "      <td>0.280997</td>\n",
       "      <td>0.250408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259819</td>\n",
       "      <td>0.283851</td>\n",
       "      <td>0.270306</td>\n",
       "      <td>0.277417</td>\n",
       "      <td>0.281006</td>\n",
       "      <td>0.252090</td>\n",
       "      <td>0.258523</td>\n",
       "      <td>0.266719</td>\n",
       "      <td>0.270370</td>\n",
       "      <td>0.236570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.259433</td>\n",
       "      <td>0.278479</td>\n",
       "      <td>0.252867</td>\n",
       "      <td>0.263265</td>\n",
       "      <td>0.270317</td>\n",
       "      <td>0.239482</td>\n",
       "      <td>0.243582</td>\n",
       "      <td>0.254479</td>\n",
       "      <td>0.260531</td>\n",
       "      <td>0.225768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.262010</td>\n",
       "      <td>0.274468</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>0.253949</td>\n",
       "      <td>0.263418</td>\n",
       "      <td>0.230673</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>0.246966</td>\n",
       "      <td>0.255380</td>\n",
       "      <td>0.219892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.268236</td>\n",
       "      <td>0.273854</td>\n",
       "      <td>0.231170</td>\n",
       "      <td>0.247891</td>\n",
       "      <td>0.259833</td>\n",
       "      <td>0.226620</td>\n",
       "      <td>0.228386</td>\n",
       "      <td>0.245820</td>\n",
       "      <td>0.257619</td>\n",
       "      <td>0.218765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13064</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13065</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13066</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13068 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_right_hand_0  x_right_hand_1  x_right_hand_10  x_right_hand_11  \\\n",
       "0            0.265100        0.292266         0.289448         0.293812   \n",
       "1            0.259819        0.283851         0.270306         0.277417   \n",
       "2            0.259433        0.278479         0.252867         0.263265   \n",
       "3            0.262010        0.274468         0.239758         0.253949   \n",
       "4            0.268236        0.273854         0.231170         0.247891   \n",
       "...               ...             ...              ...              ...   \n",
       "13063        0.000000        0.000000         0.000000         0.000000   \n",
       "13064        0.000000        0.000000         0.000000         0.000000   \n",
       "13065        0.000000        0.000000         0.000000         0.000000   \n",
       "13066        0.000000        0.000000         0.000000         0.000000   \n",
       "13067        0.000000        0.000000         0.000000         0.000000   \n",
       "\n",
       "       x_right_hand_12  x_right_hand_13  x_right_hand_14  x_right_hand_15  \\\n",
       "0             0.295057         0.267202         0.275095         0.279875   \n",
       "1             0.281006         0.252090         0.258523         0.266719   \n",
       "2             0.270317         0.239482         0.243582         0.254479   \n",
       "3             0.263418         0.230673         0.232797         0.246966   \n",
       "4             0.259833         0.226620         0.228386         0.245820   \n",
       "...                ...              ...              ...              ...   \n",
       "13063         0.000000         0.000000         0.000000         0.000000   \n",
       "13064         0.000000         0.000000         0.000000         0.000000   \n",
       "13065         0.000000         0.000000         0.000000         0.000000   \n",
       "13066         0.000000         0.000000         0.000000         0.000000   \n",
       "13067         0.000000         0.000000         0.000000         0.000000   \n",
       "\n",
       "       x_right_hand_16  x_right_hand_17  ...  y_left_hand_19  y_left_hand_2  \\\n",
       "0             0.280997         0.250408  ...             0.0            0.0   \n",
       "1             0.270370         0.236570  ...             0.0            0.0   \n",
       "2             0.260531         0.225768  ...             0.0            0.0   \n",
       "3             0.255380         0.219892  ...             0.0            0.0   \n",
       "4             0.257619         0.218765  ...             0.0            0.0   \n",
       "...                ...              ...  ...             ...            ...   \n",
       "13063         0.000000         0.000000  ...             0.0            0.0   \n",
       "13064         0.000000         0.000000  ...             0.0            0.0   \n",
       "13065         0.000000         0.000000  ...             0.0            0.0   \n",
       "13066         0.000000         0.000000  ...             0.0            0.0   \n",
       "13067         0.000000         0.000000  ...             0.0            0.0   \n",
       "\n",
       "       y_left_hand_20  y_left_hand_3  y_left_hand_4  y_left_hand_5  \\\n",
       "0                 0.0            0.0            0.0            0.0   \n",
       "1                 0.0            0.0            0.0            0.0   \n",
       "2                 0.0            0.0            0.0            0.0   \n",
       "3                 0.0            0.0            0.0            0.0   \n",
       "4                 0.0            0.0            0.0            0.0   \n",
       "...               ...            ...            ...            ...   \n",
       "13063             0.0            0.0            0.0            0.0   \n",
       "13064             0.0            0.0            0.0            0.0   \n",
       "13065             0.0            0.0            0.0            0.0   \n",
       "13066             0.0            0.0            0.0            0.0   \n",
       "13067             0.0            0.0            0.0            0.0   \n",
       "\n",
       "       y_left_hand_6  y_left_hand_7  y_left_hand_8  y_left_hand_9  \n",
       "0                0.0            0.0            0.0            0.0  \n",
       "1                0.0            0.0            0.0            0.0  \n",
       "2                0.0            0.0            0.0            0.0  \n",
       "3                0.0            0.0            0.0            0.0  \n",
       "4                0.0            0.0            0.0            0.0  \n",
       "...              ...            ...            ...            ...  \n",
       "13063            0.0            0.0            0.0            0.0  \n",
       "13064            0.0            0.0            0.0            0.0  \n",
       "13065            0.0            0.0            0.0            0.0  \n",
       "13066            0.0            0.0            0.0            0.0  \n",
       "13067            0.0            0.0            0.0            0.0  \n",
       "\n",
       "[13068 rows x 84 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 25\n"
     ]
    }
   ],
   "source": [
    "X_test, target = padding_videos(df_test)\n",
    "y_test = padding_labels(target)\n",
    "del X_test[\"sequence_id\"] \n",
    "del X_test[\"target\"] \n",
    "\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train) + len(y_test) == len(df[\"sequence_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_X(X):\n",
    "    # Define the number of rows to be flattened\n",
    "    rows_to_flatten = max_seq_length\n",
    "\n",
    "    data_array = X.to_numpy()\n",
    "\n",
    "    # Get the number of resulting rows in the output array\n",
    "    resulting_rows = data_array.shape[0] // rows_to_flatten\n",
    "\n",
    "    # Reshape the array to have (resulting_rows, rows_to_flatten, 80) shape\n",
    "    reshaped_array = data_array[:resulting_rows * rows_to_flatten].reshape(resulting_rows, rows_to_flatten, -1)\n",
    "\n",
    "    # Flatten the reshaped array along the second axis (axis=1) to get (resulting_rows, 13600) shape\n",
    "    flattened_array = reshaped_array.reshape(resulting_rows, -1)\n",
    "\n",
    "    return flattened_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_size =  num_classes * num_timesteps * num_features\n",
    "# actual_size = X.iloc[:, :num_features].values.size\n",
    "# if expected_size != actual_size:\n",
    "#     raise ValueError(\"The total number of elements in the DataFrame does not match the expected size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = int(len(X_test)/max_seq_length)\n",
    "num_features = len(get_needed_cols())\n",
    "num_classes = len(y_test[1])\n",
    "\n",
    "X_test = X_test.values.reshape(num_samples, max_seq_length, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_train = int(len(X_train)/max_seq_length)\n",
    "num_features_train = len(get_needed_cols())\n",
    "num_classes_train = len(y_train[1])\n",
    "\n",
    "X_train = X_train.values.reshape(num_samples_train, max_seq_length, num_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = flat_X(X_train)\n",
    "# X_test = flat_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (297, 44, 84) (297, 25)\n",
      "Test: (25, 44, 84) (25, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "La entrada son las coordenadas de las manos. Cada video cuenta con n cantidad de filas, 84 columnas (21 columnas por cada coordenada y por ambas manos).\n",
    "La salida es la frase. La frase se representa por un entero que da el one hot encoder.\n",
    "\n",
    "Se usa convoluciones para resaltar las caracteristicas en la entrada. Debido a que la entrada son coordenadas normalizadas de un video, se supone que funciona igual que si la entrada fuera una imagen. Estas redes extraen caracteristicas de forma automatica para clasificar objetos luego. Al buscar patrones, se espera que pueda predecir un video que ya ha sido entrenado previamente.\n",
    "\n",
    "Se reduce el tamaño de la entrada haciendo uso de max pooling y flatten.\n",
    "\n",
    "Se hace uso de Dense para conectar entradas con salidas.\n",
    "\n",
    "Se hace uso de Dropout para evitar el sobreajuste.\n",
    "\n",
    "Relu elimina negativos. \n",
    "Sigmoid nos ayuda a obtener la probabilidad de que un ejemplo pertenezca a la clase positiva.\n",
    "Softmax hace clasificacion multiclase (en nuestro caso las palabras a predecir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length, num_features_train)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes_train, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 3s 41ms/step - loss: 3.2198 - accuracy: 0.0606\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 3.2195 - accuracy: 0.0943\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 3.2046 - accuracy: 0.0976\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 3.3125 - accuracy: 0.1145\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 3.1880 - accuracy: 0.1044\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 3.1564 - accuracy: 0.1044\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 3.1532 - accuracy: 0.1077\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 15.4076 - accuracy: 0.1044\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 4.7761 - accuracy: 0.1010\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 3.0411 - accuracy: 0.1044\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.9503 - accuracy: 0.0875\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 3.1097 - accuracy: 0.0875\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 3.1361 - accuracy: 0.0842\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 3.1190 - accuracy: 0.1044\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.9240 - accuracy: 0.1077\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.8883 - accuracy: 0.1044\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.8494 - accuracy: 0.1044\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.7813 - accuracy: 0.1010\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.7505 - accuracy: 0.0909\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.6806 - accuracy: 0.1077\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.6780 - accuracy: 0.1044\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.7145 - accuracy: 0.1044\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.6985 - accuracy: 0.1111\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.6351 - accuracy: 0.1313\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.8146 - accuracy: 0.0842\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.7572 - accuracy: 0.1111\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 2.6126 - accuracy: 0.1212\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.5461 - accuracy: 0.1448\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.5148 - accuracy: 0.1515\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.5004 - accuracy: 0.1414\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.4701 - accuracy: 0.1751\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.4303 - accuracy: 0.1684\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.5665 - accuracy: 0.1481\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.5087 - accuracy: 0.1818\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.4482 - accuracy: 0.1650\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3989 - accuracy: 0.2088\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3530 - accuracy: 0.2189\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.3473 - accuracy: 0.1852\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3001 - accuracy: 0.1852\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3622 - accuracy: 0.1650\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 2.3023 - accuracy: 0.2256\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2663 - accuracy: 0.2054\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.4300 - accuracy: 0.1717\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3821 - accuracy: 0.2121\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 3.1463 - accuracy: 0.0842\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 3.3202 - accuracy: 0.0774\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.8952 - accuracy: 0.0943\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 3.0631 - accuracy: 0.0943\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.7324 - accuracy: 0.1380\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.6843 - accuracy: 0.1212\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.7885 - accuracy: 0.1279\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.7876 - accuracy: 0.0909\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.7119 - accuracy: 0.1178\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.6628 - accuracy: 0.1246\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.6648 - accuracy: 0.1212\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.6531 - accuracy: 0.1178\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.5675 - accuracy: 0.1515\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.5035 - accuracy: 0.1481\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.4462 - accuracy: 0.1818\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.4356 - accuracy: 0.1448\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3656 - accuracy: 0.1616\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.3945 - accuracy: 0.1818\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3483 - accuracy: 0.1852\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3204 - accuracy: 0.1987\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.4738 - accuracy: 0.1751\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 2.3921 - accuracy: 0.1616\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.3081 - accuracy: 0.2088\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 2.4993 - accuracy: 0.1212\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 2.3369 - accuracy: 0.1751\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2972 - accuracy: 0.1818\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.2686 - accuracy: 0.1953\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2857 - accuracy: 0.2256\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3075 - accuracy: 0.1953\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.3178 - accuracy: 0.1717\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.2835 - accuracy: 0.2088\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.3832 - accuracy: 0.1717\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2798 - accuracy: 0.1987\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2516 - accuracy: 0.1987\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2490 - accuracy: 0.1919\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.2745 - accuracy: 0.1886\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2541 - accuracy: 0.2391\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2708 - accuracy: 0.2054\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.1539 - accuracy: 0.2525\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.1347 - accuracy: 0.2256\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.1612 - accuracy: 0.2088\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.1267 - accuracy: 0.2559\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0771 - accuracy: 0.2761\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.1443 - accuracy: 0.2290\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.1725 - accuracy: 0.2626\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0318 - accuracy: 0.2559\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.2430 - accuracy: 0.2189\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.0007 - accuracy: 0.3199\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 2.0553 - accuracy: 0.2660\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0011 - accuracy: 0.2862\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0180 - accuracy: 0.2660\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9506 - accuracy: 0.2795\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0341 - accuracy: 0.2828\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.9782 - accuracy: 0.2559\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.9595 - accuracy: 0.2963\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9118 - accuracy: 0.3030\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0917 - accuracy: 0.2492\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.9479 - accuracy: 0.2896\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.9154 - accuracy: 0.2862\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.9700 - accuracy: 0.2997\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.8493 - accuracy: 0.3333\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.8775 - accuracy: 0.3030\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.8500 - accuracy: 0.3165\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.8160 - accuracy: 0.3872\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.8289 - accuracy: 0.3502\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.8694 - accuracy: 0.3367\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0111 - accuracy: 0.2626\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.8202 - accuracy: 0.3704\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.7420 - accuracy: 0.3704\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.7219 - accuracy: 0.4074\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.7385 - accuracy: 0.4040\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.7655 - accuracy: 0.3737\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.8137 - accuracy: 0.4007\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.7721 - accuracy: 0.3670\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.7211 - accuracy: 0.3973\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.6545 - accuracy: 0.3939\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.1851 - accuracy: 0.2862\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 2.0333 - accuracy: 0.2795\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.7846 - accuracy: 0.3737\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.7671 - accuracy: 0.3872\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.7775 - accuracy: 0.3603\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.7847 - accuracy: 0.3535\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6381 - accuracy: 0.4545\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6143 - accuracy: 0.4411\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.5717 - accuracy: 0.4512\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.7068 - accuracy: 0.4276\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.7687 - accuracy: 0.3603\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6543 - accuracy: 0.3670\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6943 - accuracy: 0.3838\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5532 - accuracy: 0.4646\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6096 - accuracy: 0.4209\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.5819 - accuracy: 0.4781\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.5584 - accuracy: 0.4377\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6055 - accuracy: 0.4343\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4622 - accuracy: 0.4949\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4643 - accuracy: 0.4714\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9865 - accuracy: 0.3535\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9975 - accuracy: 0.2896\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.7530 - accuracy: 0.4007\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5565 - accuracy: 0.4377\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4716 - accuracy: 0.4411\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5263 - accuracy: 0.4613\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5660 - accuracy: 0.3973\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5608 - accuracy: 0.4242\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.4893 - accuracy: 0.4276\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4231 - accuracy: 0.4680\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.3869 - accuracy: 0.4714\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4525 - accuracy: 0.4848\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.4301 - accuracy: 0.4478\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.3257 - accuracy: 0.4949\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4185 - accuracy: 0.4646\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3490 - accuracy: 0.4949\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3143 - accuracy: 0.5253\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6207 - accuracy: 0.4478\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.4835 - accuracy: 0.4579\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4954 - accuracy: 0.4916\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.2255 - accuracy: 0.5522\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.2175 - accuracy: 0.5253\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1366 - accuracy: 0.5825\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.2583 - accuracy: 0.5320\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3887 - accuracy: 0.5017\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.2125 - accuracy: 0.5320\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1821 - accuracy: 0.5488\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.0074 - accuracy: 0.4377\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.7856 - accuracy: 0.1481\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.4473 - accuracy: 0.1717\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.1853 - accuracy: 0.2357\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.9829 - accuracy: 0.3098\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.8157 - accuracy: 0.3704\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.7690 - accuracy: 0.3502\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.7524 - accuracy: 0.3367\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6484 - accuracy: 0.4276\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5872 - accuracy: 0.4242\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5036 - accuracy: 0.4579\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6059 - accuracy: 0.4310\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 51.2079 - accuracy: 0.2963\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 2.7525 - accuracy: 0.1448\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.4025 - accuracy: 0.1987\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.0999 - accuracy: 0.2761\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.9171 - accuracy: 0.3333\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.8690 - accuracy: 0.3367\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6887 - accuracy: 0.4074\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6249 - accuracy: 0.3771\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5820 - accuracy: 0.4175\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9374 - accuracy: 0.3838\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.8146 - accuracy: 0.3502\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5857 - accuracy: 0.4512\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5073 - accuracy: 0.4882\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.4393 - accuracy: 0.4613\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3624 - accuracy: 0.4781\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4021 - accuracy: 0.5051\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.5059 - accuracy: 0.4613\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3386 - accuracy: 0.5084\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1964 - accuracy: 0.5354\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.2812 - accuracy: 0.5084\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1621 - accuracy: 0.5926\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.2436 - accuracy: 0.5387\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.2883 - accuracy: 0.5253\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3976 - accuracy: 0.5017\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5386 - accuracy: 0.4579\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.5248 - accuracy: 0.5185\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.5130 - accuracy: 0.2761\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.7019 - accuracy: 0.3771\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.5851 - accuracy: 0.4040\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.4298 - accuracy: 0.4579\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3466 - accuracy: 0.5219\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6825 - accuracy: 0.4646\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9549 - accuracy: 0.3401\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.4395 - accuracy: 0.4848\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.3251 - accuracy: 0.5051\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.2621 - accuracy: 0.5320\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1589 - accuracy: 0.5690\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1927 - accuracy: 0.5859\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.3715 - accuracy: 0.5118\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 1.1592 - accuracy: 0.5589\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1063 - accuracy: 0.5993\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.1447 - accuracy: 0.6061\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.0939 - accuracy: 0.6061\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.0972 - accuracy: 0.5791\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.1102 - accuracy: 0.6162\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.9977 - accuracy: 0.6027\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.0008 - accuracy: 0.6128\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.0593 - accuracy: 0.5825\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.3823 - accuracy: 0.6364\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 5.4379 - accuracy: 0.1886\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 6.8685 - accuracy: 0.0303\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 3.2298 - accuracy: 0.0404\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 3.1472 - accuracy: 0.0404\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 3.0990 - accuracy: 0.0640\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 3.0740 - accuracy: 0.0909\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 3.0464 - accuracy: 0.0943\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.9562 - accuracy: 0.0943\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.8502 - accuracy: 0.1010\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.7475 - accuracy: 0.1313\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.7060 - accuracy: 0.1414\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.6558 - accuracy: 0.1380\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.6000 - accuracy: 0.1616\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.5082 - accuracy: 0.1818\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.4748 - accuracy: 0.1650\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.4293 - accuracy: 0.1650\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 2.3213 - accuracy: 0.2256\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.2323 - accuracy: 0.2323\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.1918 - accuracy: 0.2458\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.1256 - accuracy: 0.2761\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.1820 - accuracy: 0.2323\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.0566 - accuracy: 0.2896\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9252 - accuracy: 0.3569\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.8623 - accuracy: 0.3906\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.0283 - accuracy: 0.3266\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.1341 - accuracy: 0.2795\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.8581 - accuracy: 0.3670\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.6752 - accuracy: 0.4411\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.7431 - accuracy: 0.3973\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.8561 - accuracy: 0.3502\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6927 - accuracy: 0.4276\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6391 - accuracy: 0.4411\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6077 - accuracy: 0.4276\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.5582 - accuracy: 0.4747\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5551 - accuracy: 0.4747\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6176 - accuracy: 0.4478\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5492 - accuracy: 0.4646\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5373 - accuracy: 0.4680\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.7163 - accuracy: 0.2963\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 11.1648 - accuracy: 0.0774\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 3.1551 - accuracy: 0.0842\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.8121 - accuracy: 0.1077\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.6860 - accuracy: 0.1077\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.5620 - accuracy: 0.1380\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.4566 - accuracy: 0.1953\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.3570 - accuracy: 0.2155\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.2707 - accuracy: 0.2391\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 2.2461 - accuracy: 0.2525\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.1528 - accuracy: 0.2795\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.1401 - accuracy: 0.2660\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.0990 - accuracy: 0.2929\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 2.0258 - accuracy: 0.2896\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 2.2331 - accuracy: 0.2525\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.3675 - accuracy: 0.2290\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 2.1908 - accuracy: 0.2727\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 2.0673 - accuracy: 0.2795\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.9688 - accuracy: 0.3131\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.8981 - accuracy: 0.3636\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.9023 - accuracy: 0.3502\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.8808 - accuracy: 0.3636\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.8230 - accuracy: 0.3906\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.8000 - accuracy: 0.3535\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.7692 - accuracy: 0.3939\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6986 - accuracy: 0.3939\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.7453 - accuracy: 0.3737\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6846 - accuracy: 0.4141\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 1.6772 - accuracy: 0.4108\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.6155 - accuracy: 0.4007\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 1.5929 - accuracy: 0.4007\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 1.5583 - accuracy: 0.4579\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 1.4889 - accuracy: 0.4512\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 1.5853 - accuracy: 0.4310\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 1s 56ms/step - loss: 1.7100 - accuracy: 0.3906\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 1.5545 - accuracy: 0.4141\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 1.5474 - accuracy: 0.4276\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 1.4815 - accuracy: 0.4343\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.4560 - accuracy: 0.4579\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.4950 - accuracy: 0.4579\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.4195 - accuracy: 0.4848\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.4954 - accuracy: 0.4478\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.3606 - accuracy: 0.4613\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.3591 - accuracy: 0.4916\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.4175 - accuracy: 0.4714\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.3254 - accuracy: 0.5286\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.2228 - accuracy: 0.5421\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.2238 - accuracy: 0.5286\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.2414 - accuracy: 0.5387\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.3293 - accuracy: 0.4949\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.2952 - accuracy: 0.5118\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.4844 - accuracy: 0.4882\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 2.2076 - accuracy: 0.2828\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.6296 - accuracy: 0.4377\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 1.4199 - accuracy: 0.5051\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.3451 - accuracy: 0.4747\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.5196 - accuracy: 0.4478\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 1.3044 - accuracy: 0.5253\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.2142 - accuracy: 0.5724\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.1501 - accuracy: 0.5825\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0881 - accuracy: 0.6364\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.0365 - accuracy: 0.6128\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0369 - accuracy: 0.6162\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0285 - accuracy: 0.6027\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.1458 - accuracy: 0.5724\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.1048 - accuracy: 0.5825\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.1475 - accuracy: 0.5758\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.2813 - accuracy: 0.6027\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.2867 - accuracy: 0.5017\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.1179 - accuracy: 0.5960\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.0786 - accuracy: 0.6364\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.9649 - accuracy: 0.6397\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 0.9920 - accuracy: 0.6061\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9596 - accuracy: 0.6330\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9356 - accuracy: 0.6296\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.0980 - accuracy: 0.5859\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.2790 - accuracy: 0.5185\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.1631 - accuracy: 0.5286\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 3.0916 - accuracy: 0.2155\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 2.3757 - accuracy: 0.2121\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 2.0563 - accuracy: 0.2694\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.8654 - accuracy: 0.3165\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.7323 - accuracy: 0.3838\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.6377 - accuracy: 0.4040\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.4976 - accuracy: 0.4646\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.4406 - accuracy: 0.4646\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.4014 - accuracy: 0.4646\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.3526 - accuracy: 0.5387\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.2989 - accuracy: 0.5320\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.4302 - accuracy: 0.4646\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.2712 - accuracy: 0.5758\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.1883 - accuracy: 0.5488\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.1111 - accuracy: 0.6229\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.0904 - accuracy: 0.6061\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.1621 - accuracy: 0.5926\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0426 - accuracy: 0.6229\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.9724 - accuracy: 0.6263\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.0188 - accuracy: 0.6397\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9285 - accuracy: 0.6599\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.8509 - accuracy: 0.6801\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.9277 - accuracy: 0.6229\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0090 - accuracy: 0.5960\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0657 - accuracy: 0.6263\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0779 - accuracy: 0.5724\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.0623 - accuracy: 0.6397\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.3010 - accuracy: 0.5219\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.3163 - accuracy: 0.5051\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0481 - accuracy: 0.6128\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9920 - accuracy: 0.6296\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.9814 - accuracy: 0.6330\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.0248 - accuracy: 0.6397\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.0269 - accuracy: 0.6532\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.9266 - accuracy: 0.6397\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9151 - accuracy: 0.6700\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9688 - accuracy: 0.6465\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0110 - accuracy: 0.6397\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.0105 - accuracy: 0.6599\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.8787 - accuracy: 0.6599\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.7871 - accuracy: 0.7071\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7588 - accuracy: 0.7071\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.8028 - accuracy: 0.7104\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.7615 - accuracy: 0.7374\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0149 - accuracy: 0.6869\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 1.1006 - accuracy: 0.6128\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.9604 - accuracy: 0.6599\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.8142 - accuracy: 0.7104\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.7937 - accuracy: 0.7071\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7147 - accuracy: 0.7340\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0337 - accuracy: 0.6734\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.2719 - accuracy: 0.5657\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.9653 - accuracy: 0.6532\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.2821 - accuracy: 0.5623\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.3990 - accuracy: 0.5758\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 1.8832 - accuracy: 0.3906\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.2355 - accuracy: 0.5185\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0918 - accuracy: 0.6296\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 1.0199 - accuracy: 0.6263\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9525 - accuracy: 0.6835\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.9510 - accuracy: 0.6498\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.8516 - accuracy: 0.7037\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.9629 - accuracy: 0.6465\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.8943 - accuracy: 0.6700\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.8171 - accuracy: 0.7104\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7482 - accuracy: 0.7239\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.7312 - accuracy: 0.7407\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7257 - accuracy: 0.7172\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7074 - accuracy: 0.7239\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7423 - accuracy: 0.7104\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.7648 - accuracy: 0.6970\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.8447 - accuracy: 0.6734\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.8340 - accuracy: 0.6700\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.7974 - accuracy: 0.6734\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.6866 - accuracy: 0.7609\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.6699 - accuracy: 0.7475\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.6475 - accuracy: 0.7744\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.6210 - accuracy: 0.7879\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7644 - accuracy: 0.6835\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.7047 - accuracy: 0.7407\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 0.5893 - accuracy: 0.7879\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.6067 - accuracy: 0.7845\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.5813 - accuracy: 0.7879\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.6073 - accuracy: 0.7912\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.5905 - accuracy: 0.7811\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7403 - accuracy: 0.7441\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.8660 - accuracy: 0.6700\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.7144 - accuracy: 0.7172\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.6400 - accuracy: 0.7677\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.5888 - accuracy: 0.7912\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.5356 - accuracy: 0.8182\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.5068 - accuracy: 0.8283\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4590 - accuracy: 0.8249\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.5248 - accuracy: 0.8047\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.5769 - accuracy: 0.8047\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.6593 - accuracy: 0.7677\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.6075 - accuracy: 0.8013\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.6685 - accuracy: 0.7542\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.7856 - accuracy: 0.7037\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.6573 - accuracy: 0.7609\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9073 - accuracy: 0.6431\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7130 - accuracy: 0.7508\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.5417 - accuracy: 0.8249\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.6223 - accuracy: 0.7778\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.5437 - accuracy: 0.8148\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.4345 - accuracy: 0.8754\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4144 - accuracy: 0.8653\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4589 - accuracy: 0.8418\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4400 - accuracy: 0.8519\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3699 - accuracy: 0.8889\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3640 - accuracy: 0.8788\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3635 - accuracy: 0.8687\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.3553 - accuracy: 0.8889\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.3313 - accuracy: 0.8889\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3848 - accuracy: 0.8721\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4109 - accuracy: 0.8620\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.8546 - accuracy: 0.7205\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.8986 - accuracy: 0.6835\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 1.1298 - accuracy: 0.6465\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.7924 - accuracy: 0.6936\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.6050 - accuracy: 0.7643\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.5531 - accuracy: 0.8182\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.4922 - accuracy: 0.8215\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4946 - accuracy: 0.8418\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4351 - accuracy: 0.8620\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4039 - accuracy: 0.8485\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4062 - accuracy: 0.8653\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.3626 - accuracy: 0.8822\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3733 - accuracy: 0.8721\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.3512 - accuracy: 0.8754\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3921 - accuracy: 0.8754\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 0.3381 - accuracy: 0.8923\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3614 - accuracy: 0.8620\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.6299 - accuracy: 0.8047\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.8811 - accuracy: 0.7340\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.8830 - accuracy: 0.7104\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.5715 - accuracy: 0.7811\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.5413 - accuracy: 0.8047\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.9156 - accuracy: 0.7003\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.7000 - accuracy: 0.7374\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.5064 - accuracy: 0.8283\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.4252 - accuracy: 0.8552\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.3927 - accuracy: 0.8990\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.3442 - accuracy: 0.9024\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3192 - accuracy: 0.9125\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.3081 - accuracy: 0.9057\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3395 - accuracy: 0.9024\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.4919 - accuracy: 0.8586\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.4628 - accuracy: 0.8418\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4051 - accuracy: 0.8620\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.3391 - accuracy: 0.8990\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.3097 - accuracy: 0.9057\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.2793 - accuracy: 0.9125\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.2652 - accuracy: 0.9293\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.2704 - accuracy: 0.9259\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.4102 - accuracy: 0.8519\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 3.6606 - accuracy: 0.6000\n",
      "Test accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Create a sequential model\n",
    "# model = Sequential()\n",
    "# model.add(Convolution2D(32, (3, 3), strides=(1, 1), input_shape=(max_seq_length, num_features_train, 1), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(25, activation='sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes_train, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 453ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Find the most likely prediction for each sample\n",
    "most_likely_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  2,  3,  4,  5, 20, 18,  4,  9, 10, 11, 17, 13, 23, 15, 16,\n",
       "       11, 17, 19, 20, 21, 11,  9, 24], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = label_encoder.inverse_transform(most_likely_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels = train_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctamente predecido en:  bathroom\n",
      "Correctamente predecido en:  dog\n",
      "Correctamente predecido en:  eat food\n",
      "Correctamente predecido en:  father\n",
      "Correctamente predecido en:  fine\n",
      "Correctamente predecido en:  help\n",
      "Correctamente predecido en:  learn\n",
      "Correctamente predecido en:  like\n",
      "Correctamente predecido en:  milk\n",
      "Correctamente predecido en:  mother\n",
      "Correctamente predecido en:  no\n",
      "Correctamente predecido en:  see you later\n",
      "Correctamente predecido en:  sign\n",
      "Correctamente predecido en:  thank you\n",
      "Correctamente predecido en:  yes\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted_labels)):\n",
    "    if (predicted_labels[i] == expected_labels[i]):\n",
    "        print(\"Correctamente predecido en: \", predicted_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(max_seq_length,num_features)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = max_seq_length * 80\n",
    "# num_timesteps = max_seq_length * num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = torch.from_numpy(X_train).float()\n",
    "# X_test = torch.from_numpy(X_test).float()\n",
    "# y_train = torch.from_numpy(y_train).float()\n",
    "# y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ASLModel(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(ASLModel, self).__init__()\n",
    "#         # RuntimeError: mat1 and mat2 shapes cannot be multiplied (6912x84 and 108x2048)\n",
    "#         # (6912x84 and 83x2048)\n",
    "\n",
    "#         self.linear1 = nn.Linear(input_size, 2048)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(2048, 1024)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.linear3 = nn.Linear(1024, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x = self.linear1(x)\n",
    "#         # x = self.relu1(x)\n",
    "#         # x = self.linear2(x)\n",
    "#         # x = self.relu2(x)\n",
    "#         # x = self.linear3(x)\n",
    "#         # print(x.shape)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Initialization\n",
    "# model = ASLModel(input_size=X_train.shape[1], output_size=y_train.shape[1]).to(device)\n",
    "# # Optimization Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preparation\n",
    "# train_data = TensorDataset(X_train, y_train)\n",
    "# test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# # DataLoader\n",
    "# BATCH_SIZE = 16\n",
    "# train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reverse the JSON dictionary\n",
    "# pred_to_char = {value: key for key, value in char_to_pred.items()}\n",
    "# def reverse_to_char(data):\n",
    "#     phrase = \"\"\n",
    "#     for i in data:\n",
    "#         phrase += str(pred_to_char.get(int(i.item())) if int(i.item()) in pred_to_char else \"_\")\n",
    "    \n",
    "#     return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RuntimeError: The size of tensor a (108) must match the size of tensor b (64) at non-singleton dimension \n",
    "# for inputs, targets in train_loader:\n",
    "#     print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 5\n",
    "# loss_fn = nn.SmoothL1Loss() \n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     train_correct = 0\n",
    "\n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # labels = labels.long()\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Calculate the loss\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "#         # Accumulate the loss\n",
    "#         train_loss += loss.item() * inputs.size(0)\n",
    "#         # Accumulate the total number of samples\n",
    "#         train_correct += inputs.size(0)\n",
    "\n",
    "#     train_loss = train_loss / train_correct\n",
    "#     train_accuracy = train_correct / len(train_data)\n",
    "\n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     test_correct = 0\n",
    "#     levenshtein_distance = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             # labels = labels.long()\n",
    "\n",
    "#             print(\"input\")\n",
    "#             print(inputs)\n",
    "#             outputs = model(inputs)     \n",
    "#             print(outputs)\n",
    "#             # Get the predicted labels\n",
    "#             _, predicted = torch.max(outputs.data, dim=1)\n",
    "#             # Calculate the loss\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             # Accumulate the loss\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             # Accumulate the total number of samples\n",
    "#             test_correct += inputs.size(0)\n",
    "\n",
    "#             print(predicted.size())\n",
    "#             outputs_array = outputs.detach().cpu().numpy()\n",
    "#             targets_array = labels.detach().cpu().numpy()\n",
    "#             # Convert predictions and targets to letter sequences\n",
    "#             pred_labels = [[pred_to_char[int(label)] for label in output if int(label) in pred_to_char ] if len(output) > 0 else [] for output in outputs_array.round()]\n",
    "#             target_labels = [[pred_to_char[label] for label in target if int(label) in pred_to_char  ] if len(target) > 0 else [] for target in targets_array.round()]\n",
    "\n",
    "#             print(\"Predicted: \", pred_labels)\n",
    "#             print(\"Expected: \", target_labels)\n",
    "#             break\n",
    "\n",
    "#             # # Calculate Levenshtein distance\n",
    "#             # levenshtein_distance += calculate_levenshtein_distance(pred_labels, target_labels)\n",
    "            \n",
    "#     # test_loss = test_loss / test_correct\n",
    "#     # test_accuracy = test_correct / len(test_data)\n",
    "#     # average_levenshtein_distance = levenshtein_distance / len(test_data)\n",
    "\n",
    "#     # Print epoch results\n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "#     # print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n",
    "#     # print(f\"Average Levenshtein Distance: {average_levenshtein_distance:.4f}\")\n",
    "#     print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
